"""
æ—¢å­˜Firestoreãƒ‡ãƒ¼ã‚¿ã‹ã‚‰file_idã‚’ä½¿ç”¨ã—ã¦ãƒ†ã‚¹ãƒˆå‡¦ç†
"""

import msal
import requests
import json
import os
import gc
import time
from datetime import datetime
from typing import List, Dict, Tuple, Optional
import vertexai
from vertexai.generative_models import GenerativeModel, Part, GenerationConfig
from google.cloud import secretmanager
from google.cloud import firestore
from google.api_core import retry, exceptions
import re

# --- è¨­å®š ---
GCP_PROJECT_ID = "uplan-knowledge-base"
LOCATION = "us-central1"
TARGET_USER_EMAIL = "info@uplan2018.onmicrosoft.com"

# æ–°ã—ã„ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³åï¼ˆæ—¥æ™‚ä»˜ãï¼‰
TEST_COLLECTION = f"Projects_Test_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

# ãƒ†ã‚¹ãƒˆå¯¾è±¡ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆç‰©ä»¶åã§æ¤œç´¢ï¼‰
TEST_PROJECT_KEYWORDS = [
    "æ¾ä¸‹é‚¸",
    "ãƒ•ãƒ«ã‚¤ãƒæ§˜ã‚ªãƒ•ã‚£ã‚¹æ–°ç¯‰å·¥äº‹",
    "è±Šä¸­ã®è²¸å€‰åº«å…¼ã‚ªãƒ•ã‚£ã‚¹",
    "ä¸‰ç”°2ä¸ç›®AP",
    "å°ã•ãªãŠè‘¬å¼"
]

# ---------------------------------------------------------

def get_secret(secret_id):
    """Secret Managerã‹ã‚‰ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã‚’å–å¾—"""
    client = secretmanager.SecretManagerServiceClient()
    name = f"projects/{GCP_PROJECT_ID}/secrets/{secret_id}/versions/latest"
    response = client.access_secret_version(request={"name": name})
    return response.payload.data.decode("UTF-8")

def get_access_token():
    """Microsoft Graph APIç”¨ã®ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—"""
    try:
        client_id = get_secret("MS_CLIENT_ID")
        tenant_id = get_secret("MS_TENANT_ID")
        client_secret = get_secret("MS_CLIENT_SECRET")

        authority = f"https://login.microsoftonline.com/{tenant_id}"
        app = msal.ConfidentialClientApplication(client_id, authority=authority, client_credential=client_secret)
        result = app.acquire_token_for_client(scopes=["https://graph.microsoft.com/.default"])
        return result.get("access_token")
    except Exception as e:
        print(f"âŒ èªè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
        return None

def extract_project_metadata(folder_path):
    """ãƒ•ã‚©ãƒ«ãƒ€ãƒ‘ã‚¹ã‹ã‚‰æ¡ˆä»¶ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º"""
    metadata = {
        "structureType": None,
        "clientName": None,
        "projectName": None
    }

    parts = folder_path.split('/')

    for i, part in enumerate(parts):
        if 'æœ¨é€ ' in part:
            metadata["structureType"] = "æœ¨é€ "
            if i + 2 < len(parts):
                client_folder = parts[i + 2]
                match = re.match(r'^[AT]\d+_?(.+?)(?:ï¼ˆ.+?ï¼‰)?$', client_folder)
                if match:
                    metadata["clientName"] = match.group(1).strip()
                    break
                match2 = re.match(r'^\d+\s+(.+)$', client_folder)
                if match2:
                    metadata["clientName"] = match2.group(1).strip()
                    break
        elif 'RC' in part or 'é‰„ç­‹ã‚³ãƒ³ã‚¯ãƒªãƒ¼ãƒˆ' in part:
            metadata["structureType"] = "RCé€ "
        elif 'é‰„éª¨' in part:
            metadata["structureType"] = "Sé€ "

    for part in parts:
        if part.startswith(('2024', '2025', '2026')):
            project_part = part.split('ï¼')[0]
            match = re.match(r'^\d+_(.+)$', project_part)
            if match:
                metadata["projectName"] = match.group(1).strip()
                break

    return metadata

def select_project_files(file_list):
    """ãƒ•ã‚©ãƒ«ãƒ€å†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã€æ§‹é€ è¨ˆç®—æ›¸ãƒ»å›³é¢ãƒ»è¨¼æ˜æ›¸ãƒ»å¯©æŸ»è¡¨ã‚’é¸å®š"""
    all_calc_files = []
    all_drawing_files = []
    safety_certs = []
    review_sheets = []

    for item in file_list:
        if "folder" in item:
            continue

        name = item.get("name", "")
        name_lower = name.lower()

        if not name_lower.endswith(".pdf"):
            continue

        if "æ§‹é€ è¨ˆç®—æ›¸" in name or "è¨ˆç®—æ›¸" in name:
            all_calc_files.append(item)
        elif "æ§‹é€ å›³" in name or "ä¼å›³" in name or "è»¸çµ„å›³" in name:
            all_drawing_files.append(item)
        elif "å®‰å…¨è¨¼æ˜" in name or "é©åˆè¨¼æ˜" in name:
            safety_certs.append(item)
        elif "å¯©æŸ»è¡¨" in name or "ãƒã‚§ãƒƒã‚¯ã‚·ãƒ¼ãƒˆ" in name:
            review_sheets.append(item)

    best_cert = safety_certs[-1] if safety_certs else None
    best_review = review_sheets[-1] if review_sheets else None

    return all_calc_files, all_drawing_files, best_cert, best_review

@retry.Retry(
    predicate=retry.if_exception_type(exceptions.ResourceExhausted),
    initial=1.0,
    maximum=60.0,
    multiplier=2.0,
    timeout=300.0
)
def analyze_with_gemini_retry(file_data_list, file_name_hints=None):
    """Gemini APIã‚’å‘¼ã³å‡ºã—ï¼ˆ429ã‚¨ãƒ©ãƒ¼æ™‚ã¯è‡ªå‹•ãƒªãƒˆãƒ©ã‚¤ï¼‰"""
    return analyze_with_gemini(file_data_list, file_name_hints)

def analyze_with_gemini(file_data_list, file_name_hints=None):
    """Gemini 2.0 Flash (Vertex AI) ã§PDFã‚’è§£æ"""
    vertexai.init(project=GCP_PROJECT_ID, location=LOCATION)
    model = GenerativeModel("gemini-2.0-flash-exp")

    parts = []

    if file_name_hints:
        hint_text = "ã€ãƒ•ã‚¡ã‚¤ãƒ«åãƒ’ãƒ³ãƒˆã€‘\n" + "\n".join([f"- {hint}" for hint in file_name_hints])
        parts.append(hint_text)

    for file_info in file_data_list:
        parts.append(Part.from_data(file_info["data"], mime_type=file_info["mime_type"]))
        parts.append(f"[ãƒ•ã‚¡ã‚¤ãƒ«å: {file_info['name']}]")

    prompt = """
ä»¥ä¸‹ã®æ§‹é€ è¨ˆç®—æ›¸PDFã‚’è§£æã—ã€JSONå½¢å¼ã§æƒ…å ±ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚

ã€æŠ½å‡ºé …ç›®ã€‘
1. éƒ½é“åºœçœŒåï¼ˆprefectureï¼‰
2. æ§‹é€ ç¨®åˆ¥ï¼ˆstructureTypesï¼‰
3. ç”¨é€”ç¨®åˆ¥ï¼ˆuseTypesï¼‰
4. éšæ•°ã‚«ãƒ†ã‚´ãƒªï¼ˆfloorCategoriesï¼‰
5. å»¶ã¹é¢ç©ï¼ˆtotalAreaï¼‰
6. é¢ç©ã‚«ãƒ†ã‚´ãƒªï¼ˆareaCategoryï¼‰
7. æ€§èƒ½è¡¨ç¤ºï¼ˆperformanceLabelsï¼‰
8. è¨ˆç®—ãƒ«ãƒ¼ãƒˆï¼ˆcalcRoutesï¼‰
9. åŸºç¤å½¢å¼ï¼ˆfoundationTypesï¼‰
10. è¨­è¨ˆç‰¹è¨˜ï¼ˆfeaturesï¼‰
11. è€åŠ›è¦ç´ ï¼ˆresistanceElementsï¼‰
12. ç©é›ªåœ°åŸŸï¼ˆsnowRegionï¼‰
13. é˜²ç«åœ°åŸŸï¼ˆfireZoneï¼‰
14. åœ°ç›¤ç¨®åˆ¥ï¼ˆgroundConditionï¼‰
15. è¨ˆç®—ã‚½ãƒ•ãƒˆï¼ˆsoftwareï¼‰
16. æ¤œæŸ»æ©Ÿé–¢ï¼ˆinspectionAgencyï¼‰
17. ã‚µãƒãƒªãƒ¼ï¼ˆsummaryï¼‰

ã€å‡ºåŠ›å½¢å¼ã€‘
```json
{
  "basic": {
    "prefecture": "ç¥å¥ˆå·çœŒ",
    "structureTypes": ["æœ¨é€ "],
    "useTypes": ["å…±åŒä½å®…"],
    "floorCategories": ["3éšå»ºã¦ä»¥ä¸Š"],
    "totalArea": 850.5,
    "areaCategory": "500ã¡ä»¥ä¸Š"
  },
  "regulations": {
    "performanceLabels": ["è€éœ‡ç­‰ç´š3"],
    "calcRoutes": ["è¨±å®¹å¿œåŠ›åº¦è¨ˆç®—"],
    "calcRouteReasoning": "..."
  },
  "technology": {
    "foundationTypes": ["ã¹ãŸåŸºç¤"],
    "features": ["é‰„éª¨é€ å¤–éƒ¨éšæ®µ"],
    "resistanceElements": ["æ§‹é€ ç”¨åˆæ¿"]
  },
  "environment": {
    "snowRegion": "ä¸€èˆ¬åœ°åŸŸ",
    "fireZone": "æº–é˜²ç«åœ°åŸŸ",
    "groundCondition": "æ™®é€šåœ°ç›¤"
  },
  "management": {
    "software": "STRDESIGN Ver.17-03",
    "inspectionAgency": "æ—¥æœ¬ERI"
  },
  "analysis": {
    "summary": "..."
  }
}
```

ãã‚Œã§ã¯è§£æã‚’é–‹å§‹ã—ã¦ãã ã•ã„ã€‚
"""

    parts.insert(0, prompt)

    try:
        response = model.generate_content(
            parts,
            generation_config=GenerationConfig(
                temperature=0.1,
                top_p=0.95,
                max_output_tokens=8192,
            )
        )

        text = response.text

        if "```json" in text:
            json_str = text.split("```json")[1].split("```")[0].strip()
        elif "```" in text:
            json_str = text.split("```")[1].split("```")[0].strip()
        else:
            json_str = text.strip()

        result = json.loads(json_str)
        return result

    except Exception as e:
        print(f"âŒ Geminiè§£æã‚¨ãƒ©ãƒ¼: {e}")
        return None

def find_structure_docs_folder(access_token, user_email, parent_folder_id):
    """è¦ªãƒ•ã‚©ãƒ«ãƒ€å†…ã‹ã‚‰ã€Œæ§‹é€ è¨­è¨ˆå›³æ›¸ã€ãƒ•ã‚©ãƒ«ãƒ€ã‚’æ¢ã™"""
    headers = {"Authorization": f"Bearer {access_token}"}

    try:
        url = f"https://graph.microsoft.com/v1.0/users/{user_email}/drive/items/{parent_folder_id}/children"
        response = requests.get(url, headers=headers, timeout=30)
        response.raise_for_status()
        items = response.json().get('value', [])

        for item in items:
            if "folder" in item:
                folder_name = item['name']
                # ã€Œæ§‹é€ è¨­è¨ˆå›³æ›¸ã€ã€Œæ§‹é€ è¨ˆç®—æ›¸ã€ãªã©ã‚’å«ã‚€ãƒ•ã‚©ãƒ«ãƒ€ã‚’æ¢ã™
                if ('æ§‹é€ è¨­è¨ˆå›³æ›¸' in folder_name or 'æ§‹é€ è¨ˆç®—æ›¸' in folder_name) and 'â—‹' not in folder_name:
                    # ã•ã‚‰ã«ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€ãŒã‚ã‚‹ã‹ç¢ºèª
                    sub_url = f"https://graph.microsoft.com/v1.0/users/{user_email}/drive/items/{item['id']}/children"
                    sub_response = requests.get(sub_url, headers=headers, timeout=30)
                    if sub_response.status_code == 200:
                        sub_items = sub_response.json().get('value', [])
                        # ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€å†…ã«ã‚‚æ§‹é€ è¨­è¨ˆå›³æ›¸ãƒ•ã‚©ãƒ«ãƒ€ãŒã‚ã‚Œã°ãã¡ã‚‰ã‚’è¿”ã™
                        for sub_item in sub_items:
                            if "folder" in sub_item:
                                sub_name = sub_item['name']
                                if ('æ§‹é€ è¨­è¨ˆå›³æ›¸' in sub_name or 'æ§‹é€ è¨ˆç®—æ›¸' in sub_name) and 'â—‹' not in sub_name:
                                    return sub_item['id'], sub_item['name']

                    # ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€ãŒãªã‘ã‚Œã°ã“ã®ãƒ•ã‚©ãƒ«ãƒ€ã‚’è¿”ã™
                    return item['id'], folder_name

        return None, None

    except Exception as e:
        print(f"âš ï¸ æ§‹é€ è¨­è¨ˆå›³æ›¸ãƒ•ã‚©ãƒ«ãƒ€æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
        return None, None

def process_single_project_by_file_id(project_info: Dict, access_token: str, user_email: str) -> Tuple[bool, str, float]:
    """
    æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®file_idã‚’ä½¿ç”¨ã—ã¦æ¡ˆä»¶ã‚’å‡¦ç†
    Returns: (success: bool, message: str, elapsed_time: float)
    """
    start_time = time.time()

    headers = {"Authorization": f"Bearer {access_token}"}
    project_name = project_info.get('project_name', 'N/A')
    file_id = project_info.get('file_id')
    folder_path = project_info.get('folder_path', '')

    try:
        print(f"\nğŸ“‚ å‡¦ç†é–‹å§‹: {project_name}")

        # ã€Œæ§‹é€ è¨­è¨ˆå›³æ›¸ã€ãƒ•ã‚©ãƒ«ãƒ€ã‚’æ¢ã™
        docs_folder_id, docs_folder_name = find_structure_docs_folder(access_token, user_email, file_id)

        if not docs_folder_id:
            print(f"   âš ï¸ æ§‹é€ è¨­è¨ˆå›³æ›¸ãƒ•ã‚©ãƒ«ãƒ€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚è¦ªãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰ç›´æ¥å–å¾—ã—ã¾ã™...")
            docs_folder_id = file_id
            docs_folder_name = project_info.get('folder_name', '')
        else:
            print(f"   âœ… æ§‹é€ è¨­è¨ˆå›³æ›¸ãƒ•ã‚©ãƒ«ãƒ€è¦‹ã¤ã‹ã‚Šã¾ã—ãŸ: {docs_folder_name}")

        # ãƒ•ã‚©ãƒ«ãƒ€ã®è©³ç´°æƒ…å ±ã¨webUrlã‚’å–å¾—
        folder_detail_url = f"https://graph.microsoft.com/v1.0/users/{user_email}/drive/items/{docs_folder_id}"
        folder_detail_response = requests.get(folder_detail_url, headers=headers, timeout=30)
        folder_detail_response.raise_for_status()
        folder_detail = folder_detail_response.json()
        folder_web_url = folder_detail.get('webUrl', '')

        # ãƒ•ã‚©ãƒ«ãƒ€å†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—
        folder_url = f"https://graph.microsoft.com/v1.0/users/{user_email}/drive/items/{docs_folder_id}/children"
        response = requests.get(folder_url, headers=headers, timeout=60)
        response.raise_for_status()
        items = response.json().get('value', [])

        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸å®š
        calc_files, drawing_files, cert_file, review_file = select_project_files(items)

        if not calc_files:
            elapsed = time.time() - start_time
            return False, "æ§‹é€ è¨ˆç®—æ›¸PDFãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“", elapsed

        # PDFã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        file_data_list = []
        file_name_hints = []

        print(f"   ğŸ“¥ PDFãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­: {len(calc_files)}ãƒ•ã‚¡ã‚¤ãƒ«")
        for pdf_file in calc_files[:5]:
            download_url = pdf_file.get('@microsoft.graph.downloadUrl')
            if download_url:
                pdf_response = requests.get(download_url, timeout=120)
                if pdf_response.status_code == 200:
                    file_data_list.append({
                        "data": pdf_response.content,
                        "mime_type": "application/pdf",
                        "name": pdf_file['name']
                    })
                    file_name_hints.append(pdf_file['name'])

        if not file_data_list:
            elapsed = time.time() - start_time
            return False, "PDFãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•—", elapsed

        # Gemini APIã§è§£æ
        print(f"   ğŸ¤– AIè§£æä¸­...")
        analysis_result = analyze_with_gemini_retry(file_data_list, file_name_hints)

        del file_data_list
        gc.collect()

        if not analysis_result:
            elapsed = time.time() - start_time
            return False, "AIè§£æå¤±æ•—", elapsed

        # ãƒ•ã‚©ãƒ«ãƒ€ãƒ‘ã‚¹ã‹ã‚‰ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æŠ½å‡º
        metadata = extract_project_metadata(folder_path)

        # Firestoreã«ä¿å­˜
        db = firestore.Client(project=GCP_PROJECT_ID, database="uplan")

        timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
        safe_project_name = (project_name or "ä¸æ˜ç‰©ä»¶").replace("/", "-").replace(":", "-")
        doc_id = f"{safe_project_name}_{timestamp}"

        basic = analysis_result.get("basic", {})
        regulations = analysis_result.get("regulations", {})
        technology = analysis_result.get("technology", {})
        environment = analysis_result.get("environment", {})
        management = analysis_result.get("management", {})
        analysis = analysis_result.get("analysis", {})

        # ä½œæˆå¹´æœˆã®æŠ½å‡º
        created_year_month = None
        date_match = re.match(r'^(\d{4})(\d{2})\d{2}', docs_folder_name)
        if date_match:
            year = date_match.group(1)
            month = date_match.group(2).lstrip('0')
            created_year_month = f"{year}å¹´{month}æœˆ"

        save_data = {
            "prefecture": basic.get("prefecture"),
            "structure_types": basic.get("structureTypes", []),
            "use_types": basic.get("useTypes", []),
            "floor_categories": basic.get("floorCategories", []),
            "total_area": basic.get("totalArea", 0.0),
            "area_category": basic.get("areaCategory", ""),
            "performance_requirements": regulations.get("performanceLabels", []),
            "calc_routes": regulations.get("calcRoutes", []),
            "calc_route_reasoning": regulations.get("calcRouteReasoning", ""),
            "foundation_types": technology.get("foundationTypes", []),
            "design_features": technology.get("features", []),
            "resistance_elements": technology.get("resistanceElements", []),
            "region_conditions": {
                "snow_region": environment.get("snowRegion", ""),
                "fire_zone": environment.get("fireZone", ""),
            },
            "ground_condition": environment.get("groundCondition", ""),
            "client_name": metadata['clientName'],
            "partners": [metadata['clientName']] if metadata['clientName'] else [],
            "inspection_agency": management.get("inspectionAgency"),
            "summary": analysis.get("summary", ""),
            "analysis_result": analysis_result,
            "file_id": docs_folder_id,
            "extracted_at": firestore.SERVER_TIMESTAMP,
            "created_year_month": created_year_month,
            "project_name": project_name,
            "folder_name": docs_folder_name,
            "folder_path": folder_path,
            "folder_url": folder_web_url,
            "file_count": {
                "calc": len(calc_files),
                "drawing": len(drawing_files),
                "cert": 1 if cert_file else 0,
                "review": 1 if review_file else 0
            }
        }

        print(f"   ğŸ’¾ Firestoreä¿å­˜ä¸­...")
        collection_ref = db.collection(TEST_COLLECTION)
        collection_ref.document(doc_id).set(save_data)

        elapsed = time.time() - start_time
        return True, f"æˆåŠŸ: {len(calc_files)}ãƒ•ã‚¡ã‚¤ãƒ«è§£æ", elapsed

    except Exception as e:
        elapsed = time.time() - start_time
        return False, f"ã‚¨ãƒ©ãƒ¼: {str(e)[:100]}", elapsed

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("=" * 80)
    print("ğŸ§ª ç‰¹å®šæ¡ˆä»¶ãƒ†ã‚¹ãƒˆå®Ÿè¡Œï¼ˆæ—¢å­˜ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ï¼‰")
    print("=" * 80)
    print(f"ğŸ“Š ãƒ†ã‚¹ãƒˆã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³: {TEST_COLLECTION}")
    print("=" * 80)

    overall_start = time.time()

    # Firestoreã‹ã‚‰æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    db = firestore.Client(project=GCP_PROJECT_ID, database="uplan")
    collection_ref = db.collection("Projects_2026_01_07")

    test_projects = []

    print("\nğŸ” å¯¾è±¡æ¡ˆä»¶ã‚’æ¤œç´¢ä¸­...")
    for keyword in TEST_PROJECT_KEYWORDS:
        # project_nameã§éƒ¨åˆ†ä¸€è‡´æ¤œç´¢ï¼ˆå®Œå…¨ãªæ¤œç´¢ã¯ã§ããªã„ã®ã§ã€å–å¾—ã—ã¦ã‹ã‚‰ãƒ•ã‚£ãƒ«ã‚¿ï¼‰
        docs = collection_ref.order_by("extracted_at", direction=firestore.Query.DESCENDING).limit(100).stream()

        for doc in docs:
            data = doc.to_dict()
            project_name = data.get('project_name', '')
            if keyword in project_name:
                test_projects.append({
                    'doc_id': doc.id,
                    'project_name': project_name,
                    'file_id': data.get('file_id'),
                    'folder_path': data.get('folder_path', ''),
                    'folder_name': data.get('folder_name', ''),
                    'client_name': data.get('client_name', 'N/A')
                })
                print(f"   âœ… è¦‹ã¤ã‹ã‚Šã¾ã—ãŸ: {project_name}")
                break

    print(f"\nğŸ“‚ å¯¾è±¡æ¡ˆä»¶æ•°: {len(test_projects)}\n")

    if len(test_projects) == 0:
        print("âŒ å¯¾è±¡æ¡ˆä»¶ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        return

    # èªè¨¼
    token = get_access_token()
    if not token:
        print("âŒ èªè¨¼å¤±æ•—ã®ãŸã‚çµ‚äº†ã—ã¾ã™")
        return

    results = []

    # å„æ¡ˆä»¶ã‚’é †æ¬¡å‡¦ç†
    for i, project_info in enumerate(test_projects, 1):
        print(f"\n[{i}/{len(test_projects)}] {project_info['project_name']}")
        print(f"   å–å¼•å…ˆ: {project_info['client_name']}")
        success, message, elapsed = process_single_project_by_file_id(project_info, token, TARGET_USER_EMAIL)

        results.append({
            "project": project_info['project_name'],
            "success": success,
            "message": message,
            "elapsed": elapsed
        })

        if success:
            print(f"   âœ… {message} (å‡¦ç†æ™‚é–“: {elapsed:.1f}ç§’)")
        else:
            print(f"   âŒ {message} (å‡¦ç†æ™‚é–“: {elapsed:.1f}ç§’)")

        if i < len(test_projects):
            time.sleep(2)

    overall_elapsed = time.time() - overall_start

    # çµæœã‚µãƒãƒªãƒ¼
    print("\n" + "=" * 80)
    print("ğŸ“Š ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼")
    print("=" * 80)

    success_count = sum(1 for r in results if r["success"])
    total_processing_time = sum(r["elapsed"] for r in results)
    avg_time = total_processing_time / len(results) if results else 0

    print(f"âœ… æˆåŠŸ: {success_count}/{len(test_projects)}ä»¶")
    print(f"âŒ å¤±æ•—: {len(test_projects) - success_count}/{len(test_projects)}ä»¶")
    print(f"â±ï¸  ç·å®Ÿè¡Œæ™‚é–“: {overall_elapsed:.1f}ç§’ ({overall_elapsed/60:.1f}åˆ†)")
    print(f"â±ï¸  å¹³å‡å‡¦ç†æ™‚é–“/ä»¶: {avg_time:.1f}ç§’")
    print(f"ğŸ’¾ ä¿å­˜å…ˆ: Firestore > {TEST_COLLECTION}")
    print("=" * 80)

    # è©³ç´°çµæœ
    print("\nğŸ“‹ è©³ç´°çµæœ:")
    for i, result in enumerate(results, 1):
        status = "âœ…" if result["success"] else "âŒ"
        print(f"{i}. {status} {result['project']} - {result['message']} ({result['elapsed']:.1f}ç§’)")

if __name__ == "__main__":
    main()
