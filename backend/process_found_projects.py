"""
è¦‹ã¤ã‹ã£ãŸæ¡ˆä»¶ã‚’å‡¦ç†
- 2025012_ï¼ˆä»®ç§°ï¼‰å°ã•ãªãŠè‘¬å¼ åå¤å±‹æ˜­å’ŒåŒºãƒ›ãƒ¼ãƒ«
- 279 A1ãƒ»IDè¨­è¨ˆ ãƒ•ã‚©ãƒ«ãƒ€é…ä¸‹ã®æ¡ˆä»¶
"""

import time
from search_and_process import *

# ç‰¹å®šã®ãƒ•ã‚©ãƒ«ãƒ€åã§æ¤œç´¢
SPECIFIC_FOLDERS = [
    "2025012_ï¼ˆä»®ç§°ï¼‰å°ã•ãªãŠè‘¬å¼ åå¤å±‹æ˜­å’ŒåŒºãƒ›ãƒ¼ãƒ«",
    "279 A1ãƒ»IDè¨­è¨ˆ"
]

def find_specific_folder(access_token, folder_name):
    """ç‰¹å®šã®ãƒ•ã‚©ãƒ«ãƒ€åã§æ¤œç´¢"""
    headers = {"Authorization": f"Bearer {access_token}"}

    print(f"\nğŸ” æ¤œç´¢ä¸­: {folder_name}")

    search_url = f"https://graph.microsoft.com/v1.0/users/{TARGET_USER_EMAIL}/drive/root/search(q='{folder_name}')"

    try:
        response = requests.get(search_url, headers=headers, timeout=30)
        response.raise_for_status()
        results = response.json().get('value', [])

        folders = [item for item in results if 'folder' in item and item.get('name') == folder_name]

        if folders:
            print(f"âœ… è¦‹ã¤ã‹ã‚Šã¾ã—ãŸ: {len(folders)}ä»¶")
            folder = folders[0]  # æœ€åˆã®ä¸€è‡´
            parent_path = folder.get('parentReference', {}).get('path', '')
            if '/drive/root:' in parent_path:
                parent_path = parent_path.replace('/drive/root:', '')
            full_path = f"{parent_path}/{folder['name']}".lstrip('/')

            return {
                'id': folder['id'],
                'name': folder['name'],
                'path': full_path,
                'webUrl': folder.get('webUrl', '')
            }
        else:
            print(f"âš ï¸ è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            return None

    except Exception as e:
        print(f"âŒ æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
        return None

def find_structure_docs_in_folder(access_token, parent_folder_id):
    """è¦ªãƒ•ã‚©ãƒ«ãƒ€å†…ã‹ã‚‰æ§‹é€ è¨­è¨ˆå›³æ›¸ãƒ•ã‚©ãƒ«ãƒ€ã‚’æ¢ã™ï¼ˆå†å¸°çš„ï¼‰"""
    headers = {"Authorization": f"Bearer {access_token}"}

    try:
        url = f"https://graph.microsoft.com/v1.0/users/{TARGET_USER_EMAIL}/drive/items/{parent_folder_id}/children"
        response = requests.get(url, headers=headers, timeout=30)
        response.raise_for_status()
        items = response.json().get('value', [])

        structure_folders = []

        for item in items:
            if 'folder' in item:
                folder_name = item['name']

                # æ§‹é€ è¨­è¨ˆå›³æ›¸ãƒ•ã‚©ãƒ«ãƒ€ã‚’æ¢ã™
                if ('æ§‹é€ è¨­è¨ˆå›³æ›¸' in folder_name or 'æ§‹é€ è¨ˆç®—æ›¸' in folder_name) and 'â—‹' not in folder_name:
                    parent_path = item.get('parentReference', {}).get('path', '')
                    if '/drive/root:' in parent_path:
                        parent_path = parent_path.replace('/drive/root:', '')
                    full_path = f"{parent_path}/{folder_name}".lstrip('/')

                    structure_folders.append({
                        'id': item['id'],
                        'name': folder_name,
                        'path': full_path,
                        'webUrl': item.get('webUrl', '')
                    })
                else:
                    # ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€ã‚’å†å¸°çš„ã«æ¢ç´¢
                    sub_folders = find_structure_docs_in_folder(access_token, item['id'])
                    structure_folders.extend(sub_folders)

        return structure_folders

    except Exception as e:
        print(f"âš ï¸ ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€æ¢ç´¢ã‚¨ãƒ©ãƒ¼: {e}")
        return []

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("=" * 80)
    print("ğŸ” è¦‹ã¤ã‹ã£ãŸæ¡ˆä»¶ã‚’å‡¦ç†")
    print("=" * 80)
    print(f"ğŸ“Š ä¿å­˜å…ˆã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³: {TEST_COLLECTION}")
    print("=" * 80)

    overall_start = time.time()

    # èªè¨¼
    token = get_access_token()
    if not token:
        print("âŒ èªè¨¼å¤±æ•—ã®ãŸã‚çµ‚äº†ã—ã¾ã™")
        return

    all_target_folders = []

    # å°ã•ãªãŠè‘¬å¼ã®ãƒ•ã‚©ãƒ«ãƒ€ã‚’æ¢ã™
    osousiki_folder = find_specific_folder(token, SPECIFIC_FOLDERS[0])
    if osousiki_folder:
        print(f"   ãƒ‘ã‚¹: {osousiki_folder['path']}")

        # ã“ã®ãƒ•ã‚©ãƒ«ãƒ€å†…ã®æ§‹é€ è¨­è¨ˆå›³æ›¸ãƒ•ã‚©ãƒ«ãƒ€ã‚’æ¢ã™
        print(f"   ğŸ” æ§‹é€ è¨­è¨ˆå›³æ›¸ãƒ•ã‚©ãƒ«ãƒ€ã‚’æ¢ç´¢ä¸­...")
        structure_folders = find_structure_docs_in_folder(token, osousiki_folder['id'])

        if structure_folders:
            print(f"   âœ… {len(structure_folders)}ä»¶ã®æ§‹é€ è¨­è¨ˆå›³æ›¸ãƒ•ã‚©ãƒ«ãƒ€ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
            for sf in structure_folders:
                print(f"      ğŸ“‚ {sf['name']}")
                all_target_folders.append(sf)
        else:
            # æ§‹é€ è¨­è¨ˆå›³æ›¸ãƒ•ã‚©ãƒ«ãƒ€ãŒãªã„å ´åˆã¯è¦ªãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½¿ã†
            print(f"   âš ï¸ æ§‹é€ è¨­è¨ˆå›³æ›¸ãƒ•ã‚©ãƒ«ãƒ€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚è¦ªãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
            all_target_folders.append(osousiki_folder)

    # A1ãƒ»IDè¨­è¨ˆãƒ•ã‚©ãƒ«ãƒ€ã‚’æ¢ã™
    a1id_folder = find_specific_folder(token, SPECIFIC_FOLDERS[1])
    if a1id_folder:
        print(f"   ãƒ‘ã‚¹: {a1id_folder['path']}")

        # ã“ã®ãƒ•ã‚©ãƒ«ãƒ€å†…ã®æ¡ˆä»¶ãƒ•ã‚©ãƒ«ãƒ€ã‚’æ¢ã™
        print(f"   ğŸ” æ¡ˆä»¶ãƒ•ã‚©ãƒ«ãƒ€ã‚’æ¢ç´¢ä¸­...")
        structure_folders = find_structure_docs_in_folder(token, a1id_folder['id'])

        if structure_folders:
            print(f"   âœ… {len(structure_folders)}ä»¶ã®æ§‹é€ è¨­è¨ˆå›³æ›¸ãƒ•ã‚©ãƒ«ãƒ€ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
            # ã€Œå°ã•ãªãŠè‘¬å¼ã€ã‚’å«ã‚€ã‚‚ã®ã ã‘ã‚’é¸æŠ
            for sf in structure_folders:
                if 'å°ã•ãªãŠè‘¬å¼' in sf['path'] or 'åå¤å±‹æ˜­å’ŒåŒº' in sf['path']:
                    print(f"      ğŸ“‚ {sf['name']}")
                    all_target_folders.append(sf)

    if not all_target_folders:
        print("\nâŒ å‡¦ç†å¯¾è±¡ãƒ•ã‚©ãƒ«ãƒ€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        return

    print(f"\nğŸ“‚ å‡¦ç†å¯¾è±¡: {len(all_target_folders)}ä»¶")

    results = []

    # å„ãƒ•ã‚©ãƒ«ãƒ€ã‚’å‡¦ç†
    for i, folder_info in enumerate(all_target_folders, 1):
        print(f"\n[{i}/{len(all_target_folders)}] {folder_info['name']}")

        # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–
        if i > 1:
            print("   â³ ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–ã®ãŸã‚60ç§’å¾…æ©Ÿ...")
            time.sleep(60)
        else:
            print("   â³ åˆå›å®Ÿè¡Œå‰ã«30ç§’å¾…æ©Ÿ...")
            time.sleep(30)

        success, message, elapsed = process_folder(folder_info, token, TARGET_USER_EMAIL)

        results.append({
            "folder": folder_info['name'],
            "path": folder_info['path'],
            "success": success,
            "message": message,
            "elapsed": elapsed
        })

        if success:
            print(f"   âœ… {message} (å‡¦ç†æ™‚é–“: {elapsed:.1f}ç§’)")
        else:
            print(f"   âŒ {message} (å‡¦ç†æ™‚é–“: {elapsed:.1f}ç§’)")

    overall_elapsed = time.time() - overall_start

    # çµæœã‚µãƒãƒªãƒ¼
    print("\n" + "=" * 80)
    print("ğŸ“Š å‡¦ç†çµæœã‚µãƒãƒªãƒ¼")
    print("=" * 80)

    success_count = sum(1 for r in results if r["success"])
    total_processing_time = sum(r["elapsed"] for r in results)
    avg_time = total_processing_time / len(results) if results else 0

    print(f"âœ… æˆåŠŸ: {success_count}/{len(results)}ä»¶")
    print(f"âŒ å¤±æ•—: {len(results) - success_count}/{len(results)}ä»¶")
    print(f"â±ï¸  ç·å®Ÿè¡Œæ™‚é–“: {overall_elapsed:.1f}ç§’ ({overall_elapsed/60:.1f}åˆ†)")
    print(f"â±ï¸  å¹³å‡å‡¦ç†æ™‚é–“: {avg_time:.1f}ç§’/ä»¶")
    print(f"ğŸ’¾ ä¿å­˜å…ˆ: Firestore > {TEST_COLLECTION}")
    print("=" * 80)

    # è©³ç´°çµæœ
    print("\nğŸ“‹ è©³ç´°çµæœ:")
    for i, result in enumerate(results, 1):
        status = "âœ…" if result["success"] else "âŒ"
        print(f"{i}. {status} {result['folder']}")
        print(f"   ãƒ‘ã‚¹: {result['path']}")
        print(f"   çµæœ: {result['message']} ({result['elapsed']:.1f}ç§’)")

if __name__ == "__main__":
    main()
