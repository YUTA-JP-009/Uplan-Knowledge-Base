"""
Uplan Knowledge Base - Batch Processor v3 (Parallel Processing Edition)

ä¸¦åˆ—å‡¦ç†å¯¾å¿œç‰ˆ:
- ProcessPoolExecutor ã«ã‚ˆã‚‹5ä¸¦åˆ—å‡¦ç†
- ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã§ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ‘ã‚¹æŒ‡å®š
- é€²æ—ç®¡ç†ã¨ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¼·åŒ–
- Cloud Run Jobså¯¾å¿œ
"""

import msal
import requests
import json
import os
import gc
import argparse
import time
from concurrent.futures import ProcessPoolExecutor, as_completed
from typing import List, Dict, Tuple, Optional
import vertexai
from vertexai.generative_models import GenerativeModel, Part, GenerationConfig
from google.cloud import secretmanager
from google.cloud import firestore
from google.api_core import retry, exceptions

# --- è¨­å®š ---
GCP_PROJECT_ID = "uplan-knowledge-base"
LOCATION = "us-central1"
TARGET_USER_EMAIL = "info@uplan2018.onmicrosoft.com"

# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šï¼ˆã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã§ä¸Šæ›¸ãå¯èƒ½ï¼‰
DEFAULT_TARGET_PATH = "001_ï¼µ'plan_å…¨ç¤¾/01.æ§‹é€ è¨­è¨ˆ/01.æœ¨é€ ï¼ˆåœ¨æ¥è»¸çµ„ï¼‰"
DEFAULT_MAX_WORKERS = 5
# ---------------------------------------------------------

# 1. èªè¨¼å‘¨ã‚Š
def get_secret(secret_id):
    """Secret Managerã‹ã‚‰ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã‚’å–å¾—"""
    client = secretmanager.SecretManagerServiceClient()
    name = f"projects/{GCP_PROJECT_ID}/secrets/{secret_id}/versions/latest"
    response = client.access_secret_version(request={"name": name})
    return response.payload.data.decode("UTF-8")

def get_access_token():
    """Microsoft Graph APIç”¨ã®ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—"""
    try:
        client_id = get_secret("MS_CLIENT_ID")
        tenant_id = get_secret("MS_TENANT_ID")
        client_secret = get_secret("MS_CLIENT_SECRET")

        authority = f"https://login.microsoftonline.com/{tenant_id}"
        app = msal.ConfidentialClientApplication(client_id, authority=authority, client_credential=client_secret)
        result = app.acquire_token_for_client(scopes=["https://graph.microsoft.com/.default"])
        return result.get("access_token")
    except Exception as e:
        print(f"âŒ èªè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
        return None

# 1-2. ã‚·ã‚¹ãƒ†ãƒ è¨­å®šç®¡ç†ï¼ˆãƒ‡ãƒ«ã‚¿ã‚¯ã‚¨ãƒªç”¨ã‚¹ã‚¿ãƒ³ãƒ—ï¼‰
def get_system_config():
    """Firestoreã‹ã‚‰ã‚·ã‚¹ãƒ†ãƒ è¨­å®šï¼ˆå‰å›ã®åŒæœŸçŠ¶æ…‹ï¼‰ã‚’å–å¾—"""
    try:
        db = firestore.Client(project=GCP_PROJECT_ID, database="uplan")
        doc_ref = db.collection("system_config").document("onedrive_sync")
        doc = doc_ref.get()
        if doc.exists:
            return doc.to_dict()
        return None
    except Exception as e:
        print(f"âš ï¸ ã‚·ã‚¹ãƒ†ãƒ è¨­å®šå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return None

def save_system_config(delta_link):
    """Firestoreã«ã‚·ã‚¹ãƒ†ãƒ è¨­å®šï¼ˆåŒæœŸçŠ¶æ…‹ï¼‰ã‚’ä¿å­˜"""
    try:
        db = firestore.Client(project=GCP_PROJECT_ID, database="uplan")
        doc_ref = db.collection("system_config").document("onedrive_sync")
        doc_ref.set({
            "deltaLink": delta_link,
            "last_run_at": firestore.SERVER_TIMESTAMP
        })
        print(f"âœ… ãƒ‡ãƒ«ã‚¿ãƒªãƒ³ã‚¯ã‚’ä¿å­˜ã—ã¾ã—ãŸ")
    except Exception as e:
        print(f"âŒ ã‚·ã‚¹ãƒ†ãƒ è¨­å®šä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")

# 2. ãƒ‘ã‚¹æƒ…å ±æŠ½å‡ºãƒ­ã‚¸ãƒƒã‚¯
def extract_project_metadata(folder_path):
    """
    ãƒ•ã‚©ãƒ«ãƒ€ãƒ‘ã‚¹ã‹ã‚‰æ¡ˆä»¶ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
    ä¾‹: "001_ï¼µ'plan_å…¨ç¤¾/01.æ§‹é€ è¨­è¨ˆ/01.æœ¨é€ ï¼ˆåœ¨æ¥è»¸çµ„ï¼‰/â–¡ã‚è¡Œ/A00698ã‚¢ã‚¼ãƒªã‚¢ãƒ›ãƒ¼ãƒ /..."
    """
    metadata = {
        "structureType": None,
        "clientName": None,
        "projectName": None
    }

    parts = folder_path.split('/')

    # 1. å–å¼•å…ˆåã®æŠ½å‡º
    # åŸºæœ¬æ§‹é€ : æœ¨é€ ï¼ˆåœ¨æ¥è»¸çµ„ï¼‰> â–¡ã‚è¡Œ > å–å¼•å…ˆå
    # æœ¨é€ ãƒ•ã‚©ãƒ«ãƒ€ã‚’èµ·ç‚¹ã«3éšå±¤ç›®ãŒå–å¼•å…ˆå
    for i, part in enumerate(parts):
        if 'æœ¨é€ ' in part:
            metadata["structureType"] = "æœ¨é€ "
            if i + 2 < len(parts):
                client_folder = parts[i + 2]
                # ãƒ‘ã‚¿ãƒ¼ãƒ³1: "Aæ•°å­—_å–å¼•å…ˆå" ã¾ãŸã¯ "Aæ•°å­—å–å¼•å…ˆå"ï¼ˆã‚¢ãƒ³ãƒ€ãƒ¼ãƒãƒ¼ã‚ã‚Šãƒ»ãªã—å¯¾å¿œï¼‰
                import re
                match = re.match(r'^[AT]\d+_?(.+?)(?:ï¼ˆ.+?ï¼‰)?$', client_folder)
                if match:
                    metadata["clientName"] = match.group(1).strip()
                    break
        elif 'RC' in part or 'é‰„ç­‹ã‚³ãƒ³ã‚¯ãƒªãƒ¼ãƒˆ' in part:
            metadata["structureType"] = "RCé€ "
        elif 'é‰„éª¨' in part:
            metadata["structureType"] = "Sé€ "

    # 2. æ¡ˆä»¶åã®æŠ½å‡º
    # "2024009_ï¼ˆä»®ç§°ï¼‰ä¸‰ç”°2ä¸ç›®APï¼2024010_è¨­è¨ˆå¤‰æ›´" ã®ã‚ˆã†ãªãƒ•ã‚©ãƒ«ãƒ€åã‹ã‚‰æŠ½å‡º
    for part in parts:
        if part.startswith(('2024', '2025', '2026')):
            # "ï¼" ã§åˆ†å‰²ã—ã¦æœ€åˆã®éƒ¨åˆ†ã‚’æ¡ˆä»¶åã¨ã™ã‚‹
            project_part = part.split('ï¼')[0]
            # "2024009_" ã®ã‚ˆã†ãªç•ªå·éƒ¨åˆ†ã‚’é™¤å»
            import re
            match = re.match(r'^\d+_(.+)$', project_part)
            if match:
                metadata["projectName"] = match.group(1).strip()
                break

    return metadata

# 3. ãƒ•ã‚¡ã‚¤ãƒ«é¸å®šãƒ­ã‚¸ãƒƒã‚¯
def select_project_files(file_list):
    """
    ãƒ•ã‚©ãƒ«ãƒ€å†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã€æ§‹é€ è¨ˆç®—æ›¸ãƒ»å›³é¢ãƒ»è¨¼æ˜æ›¸ãƒ»å¯©æŸ»è¡¨ã‚’é¸å®š
    """
    all_calc_files = []
    all_drawing_files = []
    safety_certs = []
    review_sheets = []

    for item in file_list:
        if "folder" in item:
            continue

        name = item.get("name", "")
        name_lower = name.lower()

        if not name_lower.endswith(".pdf"):
            continue

        # æ§‹é€ è¨ˆç®—æ›¸
        if "æ§‹é€ è¨ˆç®—æ›¸" in name or "è¨ˆç®—æ›¸" in name:
            all_calc_files.append(item)

        # æ§‹é€ å›³
        elif "æ§‹é€ å›³" in name or "ä¼å›³" in name or "è»¸çµ„å›³" in name:
            all_drawing_files.append(item)

        # å®‰å…¨è¨¼æ˜æ›¸
        elif "å®‰å…¨è¨¼æ˜" in name or "é©åˆè¨¼æ˜" in name:
            safety_certs.append(item)

        # æ§‹é€ å¯©æŸ»è¡¨
        elif "å¯©æŸ»è¡¨" in name or "ãƒã‚§ãƒƒã‚¯ã‚·ãƒ¼ãƒˆ" in name:
            review_sheets.append(item)

    # æœ€æ–°ã®è¨¼æ˜æ›¸ã¨å¯©æŸ»è¡¨ã‚’é¸æŠ
    best_cert = safety_certs[-1] if safety_certs else None
    best_review = review_sheets[-1] if review_sheets else None

    return all_calc_files, all_drawing_files, best_cert, best_review

# 4. ãƒ‡ãƒ«ã‚¿ã‚¯ã‚¨ãƒªã«ã‚ˆã‚‹å·®åˆ†å–å¾—
def fetch_drive_changes(access_token, user_email, delta_link=None):
    """Microsoft Graph APIã®ãƒ‡ãƒ«ã‚¿ã‚¯ã‚¨ãƒªã‚’ä½¿ç”¨ã—ã¦ã€å‰å›ã‹ã‚‰ã®å¤‰æ›´ã‚’å–å¾—"""
    headers = {"Authorization": f"Bearer {access_token}"}
    changed_items = []

    if delta_link is None:
        url = f"https://graph.microsoft.com/v1.0/users/{user_email}/drive/root:/delta"
        print(f"ğŸ“ åˆå›ãƒ‡ãƒ«ã‚¿ã‚¯ã‚¨ãƒªå®Ÿè¡Œ")
    else:
        url = delta_link
        print(f"ğŸ“ å·®åˆ†å–å¾—ãƒ¢ãƒ¼ãƒ‰: å‰å›ã‹ã‚‰ã®å¤‰æ›´ã®ã¿ã‚’å–å¾—")

    try:
        while url:
            response = requests.get(url, headers=headers)
            response.raise_for_status()
            data = response.json()

            items = data.get('value', [])
            for item in items:
                if 'deleted' in item:
                    continue
                if 'file' in item and item.get('name', '').lower().endswith('.pdf'):
                    changed_items.append(item)
                if 'folder' in item:
                    changed_items.append(item)

            url = data.get('@odata.nextLink')
            if not url:
                new_delta_link = data.get('@odata.deltaLink')
                break

        print(f"âœ… ãƒ‡ãƒ«ã‚¿ã‚¯ã‚¨ãƒªå®Œäº†: {len(changed_items)}ä»¶ã®å¤‰æ›´ã‚’æ¤œå‡º")
        return changed_items, new_delta_link

    except Exception as e:
        print(f"âŒ ãƒ‡ãƒ«ã‚¿ã‚¯ã‚¨ãƒªã‚¨ãƒ©ãƒ¼: {e}")
        return [], None

# 5. ãƒ•ã‚©ãƒ«ãƒ€åé›†ï¼ˆä¸¦åˆ—å‡¦ç†ç”¨ï¼‰
def collect_all_project_folders(access_token, user_email, root_path):
    """
    æŒ‡å®šã•ã‚ŒãŸãƒ«ãƒ¼ãƒˆãƒ‘ã‚¹é…ä¸‹ã®å…¨ã¦ã®æ§‹é€ è¨­è¨ˆå›³æ›¸ãƒ•ã‚©ãƒ«ãƒ€ã‚’åé›†
    Returns: List[Dict] - æ¡ˆä»¶ãƒ•ã‚©ãƒ«ãƒ€æƒ…å ±ã®ãƒªã‚¹ãƒˆ
    """
    headers = {"Authorization": f"Bearer {access_token}"}
    project_folders = []

    print(f"ğŸ“‚ ãƒ•ã‚©ãƒ«ãƒ€åé›†é–‹å§‹: {root_path}")

    def scan_folder_recursive(folder_url, current_path=""):
        """å†å¸°çš„ã«ãƒ•ã‚©ãƒ«ãƒ€ã‚’ã‚¹ã‚­ãƒ£ãƒ³"""
        try:
            response = requests.get(folder_url, headers=headers, timeout=30)
            response.raise_for_status()
            items = response.json().get('value', [])

            for item in items:
                if "folder" not in item:
                    continue

                folder_name = item['name']
                folder_id = item['id']
                new_path = f"{current_path}/{folder_name}".lstrip('/')

                # æ§‹é€ è¨­è¨ˆå›³æ›¸ãƒ•ã‚©ãƒ«ãƒ€ã‚’æ¤œå‡ºï¼ˆãƒ€ãƒŸãƒ¼ãƒ•ã‚©ãƒ«ãƒ€é™¤å¤–ï¼‰
                if ('æ§‹é€ è¨­è¨ˆå›³æ›¸' in folder_name or 'æ§‹é€ è¨ˆç®—æ›¸' in folder_name) and 'â—‹' not in folder_name:
                    # ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€ï¼ˆç´å“æ™‚ãªã©ï¼‰ã‚‚æ¢ç´¢
                    sub_url = f"https://graph.microsoft.com/v1.0/users/{user_email}/drive/items/{folder_id}/children"
                    sub_response = requests.get(sub_url, headers=headers, timeout=30)
                    if sub_response.status_code == 200:
                        sub_items = sub_response.json().get('value', [])

                        # ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€å†…ã«ã‚‚æ§‹é€ è¨­è¨ˆå›³æ›¸ãƒ•ã‚©ãƒ«ãƒ€ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                        has_sub_folders = False
                        for sub_item in sub_items:
                            if "folder" in sub_item:
                                sub_name = sub_item['name']
                                if ('æ§‹é€ è¨­è¨ˆå›³æ›¸' in sub_name or 'æ§‹é€ è¨ˆç®—æ›¸' in sub_name) and 'â—‹' not in sub_name:
                                    project_folders.append({
                                        'id': sub_item['id'],
                                        'name': sub_item['name'],
                                        'path': new_path,
                                        'full_path': f"{new_path}/{sub_item['name']}"
                                    })
                                    has_sub_folders = True

                        # ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€ãŒãªã‘ã‚Œã°ã€ã“ã®ãƒ•ã‚©ãƒ«ãƒ€è‡ªä½“ã‚’è¿½åŠ 
                        if not has_sub_folders:
                            project_folders.append({
                                'id': folder_id,
                                'name': folder_name,
                                'path': current_path,
                                'full_path': new_path
                            })
                else:
                    # æ§‹é€ è¨­è¨ˆå›³æ›¸ãƒ•ã‚©ãƒ«ãƒ€ã§ãªã„å ´åˆã¯å†å¸°çš„ã«æ¢ç´¢
                    child_url = f"https://graph.microsoft.com/v1.0/users/{user_email}/drive/items/{folder_id}/children"
                    scan_folder_recursive(child_url, new_path)

        except requests.exceptions.Timeout:
            print(f"âš ï¸ ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: {current_path}")
        except Exception as e:
            print(f"âš ï¸ ãƒ•ã‚©ãƒ«ãƒ€ã‚¹ã‚­ãƒ£ãƒ³ã‚¨ãƒ©ãƒ¼ ({current_path}): {e}")

    # ãƒ«ãƒ¼ãƒˆãƒ‘ã‚¹ã‹ã‚‰æ¢ç´¢é–‹å§‹
    start_url = f"https://graph.microsoft.com/v1.0/users/{user_email}/drive/root:/{root_path}:/children"
    scan_folder_recursive(start_url, root_path)

    print(f"âœ… ãƒ•ã‚©ãƒ«ãƒ€åé›†å®Œäº†: {len(project_folders)}ä»¶ã®æ¡ˆä»¶ã‚’æ¤œå‡º")
    return project_folders

# 6. Gemini APIã«ã‚ˆã‚‹è§£æï¼ˆãƒªãƒˆãƒ©ã‚¤ä»˜ãï¼‰
@retry.Retry(
    predicate=retry.if_exception_type(exceptions.ResourceExhausted),
    initial=1.0,
    maximum=60.0,
    multiplier=2.0,
    timeout=300.0
)
def analyze_with_gemini_retry(file_data_list, file_name_hints=None):
    """Gemini APIã‚’å‘¼ã³å‡ºã—ï¼ˆ429ã‚¨ãƒ©ãƒ¼æ™‚ã¯è‡ªå‹•ãƒªãƒˆãƒ©ã‚¤ï¼‰"""
    return analyze_with_gemini(file_data_list, file_name_hints)

def analyze_with_gemini(file_data_list, file_name_hints=None):
    """
    Gemini 2.0 Flash (Vertex AI) ã§PDFã‚’è§£æ
    file_data_list: [{"data": bytes, "mime_type": str, "name": str}, ...]
    """
    vertexai.init(project=GCP_PROJECT_ID, location=LOCATION)
    model = GenerativeModel("gemini-2.0-flash-exp")

    parts = []

    # ãƒ•ã‚¡ã‚¤ãƒ«åãƒ’ãƒ³ãƒˆ
    if file_name_hints:
        hint_text = "ã€ãƒ•ã‚¡ã‚¤ãƒ«åãƒ’ãƒ³ãƒˆã€‘\n" + "\n".join([f"- {hint}" for hint in file_name_hints])
        parts.append(hint_text)

    # PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¿½åŠ 
    for file_info in file_data_list:
        parts.append(Part.from_data(file_info["data"], mime_type=file_info["mime_type"]))
        parts.append(f"[ãƒ•ã‚¡ã‚¤ãƒ«å: {file_info['name']}]")

    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆç°¡ç•¥ç‰ˆ - å®Ÿéš›ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯æ—¢å­˜ã®ã‚‚ã®ã‚’ä½¿ç”¨ï¼‰
    prompt = """
ä»¥ä¸‹ã®æ§‹é€ è¨ˆç®—æ›¸PDFã‚’è§£æã—ã€JSONå½¢å¼ã§æƒ…å ±ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚

ã€æŠ½å‡ºé …ç›®ã€‘
1. éƒ½é“åºœçœŒåï¼ˆprefectureï¼‰
2. æ§‹é€ ç¨®åˆ¥ï¼ˆstructureTypesï¼‰: ["æœ¨é€ ", "RCé€ ", "Sé€ ", "æ··æ§‹é€ "]
3. ç”¨é€”ç¨®åˆ¥ï¼ˆuseTypesï¼‰: ["å…±åŒä½å®…", "äº‹å‹™æ‰€", "åº—èˆ—", "æˆ¸å»ºä½å®…", etc.]
4. éšæ•°ã‚«ãƒ†ã‚´ãƒªï¼ˆfloorCategoriesï¼‰: ["å¹³å±‹", "2éšå»ºã¦", "3éšå»ºã¦ä»¥ä¸Š"]
5. å»¶ã¹é¢ç©ï¼ˆtotalAreaï¼‰: æ•°å€¤
6. é¢ç©ã‚«ãƒ†ã‚´ãƒªï¼ˆareaCategoryï¼‰: "500ã¡æœªæº€" | "500ã¡ä»¥ä¸Š"
7. æ€§èƒ½è¡¨ç¤ºï¼ˆperformanceLabelsï¼‰: ["è€éœ‡ç­‰ç´š3", "åˆ¶æŒ¯æ§‹é€ ", etc.]
8. è¨ˆç®—ãƒ«ãƒ¼ãƒˆï¼ˆcalcRoutesï¼‰: ["ãƒ«ãƒ¼ãƒˆ1", "ãƒ«ãƒ¼ãƒˆ2", "ãƒ«ãƒ¼ãƒˆ3", "è¨±å®¹å¿œåŠ›åº¦è¨ˆç®—", "é™ç•Œè€åŠ›è¨ˆç®—"]
9. åŸºç¤å½¢å¼ï¼ˆfoundationTypesï¼‰: ["ã¹ãŸåŸºç¤", "å¸ƒåŸºç¤", "æ­åŸºç¤"]
10. è¨­è¨ˆç‰¹è¨˜ï¼ˆfeaturesï¼‰: ["é‰„éª¨é€ å¤–éƒ¨éšæ®µ", "å¹æŠœã‘", "ã‚ªãƒ¼ãƒãƒ¼ãƒãƒ³ã‚°", etc.]
11. è€åŠ›è¦ç´ ï¼ˆresistanceElementsï¼‰: ["ç­‹ã‹ã„", "æ§‹é€ ç”¨åˆæ¿", "è€åŠ›å£", etc.]
12. ç©é›ªåœ°åŸŸï¼ˆsnowRegionï¼‰: "ä¸€èˆ¬åœ°åŸŸ" | "å¤šé›ªåœ°åŸŸ"
13. é˜²ç«åœ°åŸŸï¼ˆfireZoneï¼‰: "æŒ‡å®šãªã—" | "æº–é˜²ç«åœ°åŸŸ" | "é˜²ç«åœ°åŸŸ"
14. åœ°ç›¤ç¨®åˆ¥ï¼ˆgroundConditionï¼‰: "æ™®é€šåœ°ç›¤" | "è»Ÿå¼±åœ°ç›¤"
15. è¨ˆç®—ã‚½ãƒ•ãƒˆï¼ˆsoftwareï¼‰
16. æ¤œæŸ»æ©Ÿé–¢ï¼ˆinspectionAgencyï¼‰
17. ã‚µãƒãƒªãƒ¼ï¼ˆsummaryï¼‰: æ¡ˆä»¶ã®ç‰¹å¾´ã‚’2-3æ–‡ã§è¦ç´„

ã€å‡ºåŠ›å½¢å¼ã€‘
```json
{
  "basic": {
    "prefecture": "ç¥å¥ˆå·çœŒ",
    "structureTypes": ["æœ¨é€ "],
    "useTypes": ["å…±åŒä½å®…"],
    "floorCategories": ["3éšå»ºã¦ä»¥ä¸Š"],
    "totalArea": 850.5,
    "areaCategory": "500ã¡ä»¥ä¸Š"
  },
  "regulations": {
    "performanceLabels": ["è€éœ‡ç­‰ç´š3"],
    "calcRoutes": ["è¨±å®¹å¿œåŠ›åº¦è¨ˆç®—"],
    "calcRouteReasoning": "..."
  },
  "technology": {
    "foundationTypes": ["ã¹ãŸåŸºç¤"],
    "features": ["é‰„éª¨é€ å¤–éƒ¨éšæ®µ"],
    "resistanceElements": ["æ§‹é€ ç”¨åˆæ¿"]
  },
  "environment": {
    "snowRegion": "ä¸€èˆ¬åœ°åŸŸ",
    "fireZone": "æº–é˜²ç«åœ°åŸŸ",
    "groundCondition": "æ™®é€šåœ°ç›¤"
  },
  "management": {
    "software": "STRDESIGN Ver.17-03",
    "inspectionAgency": "æ—¥æœ¬ERI"
  },
  "analysis": {
    "summary": "..."
  }
}
```

ã€é‡è¦ãªæ¤œå‡ºãƒ«ãƒ¼ãƒ«ã€‘
â˜…â˜…â˜…æœ€é‡è¦â˜…â˜…â˜… é‰„éª¨é€ å¤–éƒ¨éšæ®µã®æ¤œå‡º:
- æ§‹é€ è¨ˆç®—æ›¸ã®ç›®æ¬¡ã€æœ¬æ–‡ã€è¨ˆç®—æ›¸å†…ã«ã€Œé‰„éª¨éšæ®µã€ã€Œå¤–éƒ¨éšæ®µã€ã€Œå±‹å¤–éšæ®µã€ãªã©ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒã‚ã‚‹
- æ§‹é€ å›³é¢ã«é‰„éª¨éšæ®µã®å›³é¢ãŒã‚ã‚‹
- è¨ˆç®—æ›¸ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚„ç« ç«‹ã¦ã«ã€Œéšæ®µã€ã€Œå¤–éƒ¨éšæ®µã€ãªã©ã®è¨˜è¼‰ãŒã‚ã‚‹
â†’ ã„ãšã‚Œã‹ã«è©²å½“ã™ã‚Œã°ã€Œé‰„éª¨é€ å¤–éƒ¨éšæ®µã€ã¨ã—ã¦æŠ½å‡ºã—ã¦ãã ã•ã„

ãã‚Œã§ã¯è§£æã‚’é–‹å§‹ã—ã¦ãã ã•ã„ã€‚
"""

    parts.insert(0, prompt)

    try:
        response = model.generate_content(
            parts,
            generation_config=GenerationConfig(
                temperature=0.1,
                top_p=0.95,
                max_output_tokens=8192,
            )
        )

        text = response.text

        # JSONã‚’æŠ½å‡º
        if "```json" in text:
            json_str = text.split("```json")[1].split("```")[0].strip()
        elif "```" in text:
            json_str = text.split("```")[1].split("```")[0].strip()
        else:
            json_str = text.strip()

        result = json.loads(json_str)
        return result

    except Exception as e:
        print(f"âŒ Geminiè§£æã‚¨ãƒ©ãƒ¼: {e}")
        return None

# 7. å˜ä¸€æ¡ˆä»¶ã®å‡¦ç†ï¼ˆä¸¦åˆ—å®Ÿè¡Œã•ã‚Œã‚‹é–¢æ•°ï¼‰
def process_single_project(project_info: Dict, access_token: str, user_email: str) -> Tuple[bool, str]:
    """
    å˜ä¸€ã®æ¡ˆä»¶ãƒ•ã‚©ãƒ«ãƒ€ã‚’å‡¦ç†ï¼ˆä¸¦åˆ—å®Ÿè¡Œã•ã‚Œã‚‹ï¼‰

    Args:
        project_info: ãƒ•ã‚©ãƒ«ãƒ€æƒ…å ±
        access_token: ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³
        user_email: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹

    Returns:
        (success: bool, message: str)
    """
    folder_id = project_info['id']
    folder_name = project_info['name']
    full_path = project_info['full_path']

    headers = {"Authorization": f"Bearer {access_token}"}

    try:
        # ãƒ•ã‚©ãƒ«ãƒ€å†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—
        folder_url = f"https://graph.microsoft.com/v1.0/users/{user_email}/drive/items/{folder_id}/children"
        response = requests.get(folder_url, headers=headers, timeout=60)
        response.raise_for_status()
        items = response.json().get('value', [])

        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸å®š
        calc_files, drawing_files, cert_file, review_file = select_project_files(items)

        if not calc_files:
            return False, f"æ§‹é€ è¨ˆç®—æ›¸PDFãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"

        # PDFã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        file_data_list = []
        file_name_hints = []

        for pdf_file in calc_files[:5]:  # æœ€å¤§5ãƒ•ã‚¡ã‚¤ãƒ«
            download_url = pdf_file.get('@microsoft.graph.downloadUrl')
            if download_url:
                pdf_response = requests.get(download_url, timeout=120)
                if pdf_response.status_code == 200:
                    file_data_list.append({
                        "data": pdf_response.content,
                        "mime_type": "application/pdf",
                        "name": pdf_file['name']
                    })
                    file_name_hints.append(pdf_file['name'])

        if not file_data_list:
            return False, "PDFãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•—"

        # Gemini APIã§è§£æ
        analysis_result = analyze_with_gemini_retry(file_data_list, file_name_hints)

        # ãƒ¡ãƒ¢ãƒªè§£æ”¾
        del file_data_list
        gc.collect()

        if not analysis_result:
            return False, "AIè§£æå¤±æ•—"

        # ãƒ•ã‚©ãƒ«ãƒ€ãƒ‘ã‚¹ã‹ã‚‰ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æŠ½å‡º
        metadata = extract_project_metadata(full_path)

        # Firestoreã«ä¿å­˜
        db = firestore.Client(project=GCP_PROJECT_ID, database="uplan")

        # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆIDã‚’ç”Ÿæˆï¼ˆãƒ•ã‚©ãƒ«ãƒ€IDã‚’ä½¿ç”¨ï¼‰
        doc_id = f"project_{folder_id}"

        # ä¿å­˜ãƒ‡ãƒ¼ã‚¿ã‚’æ§‹ç¯‰
        basic = analysis_result.get("basic", {})
        regulations = analysis_result.get("regulations", {})
        technology = analysis_result.get("technology", {})
        environment = analysis_result.get("environment", {})
        management = analysis_result.get("management", {})
        analysis = analysis_result.get("analysis", {})

        save_data = {
            # å»ºç¯‰ç‰©ã®ç‰¹æ€§
            "prefecture": basic.get("prefecture"),
            "structure_types": basic.get("structureTypes", []),
            "use_types": basic.get("useTypes", []),
            "floor_categories": basic.get("floorCategories", []),
            "total_area": basic.get("totalArea", 0.0),
            "area_category": basic.get("areaCategory", ""),

            # æ³•å¾‹ãƒ»æŠ€è¡“çš„è¦ä»¶
            "performance_requirements": regulations.get("performanceLabels", []),
            "calc_routes": regulations.get("calcRoutes", []),
            "calc_route_reasoning": regulations.get("calcRouteReasoning", ""),
            "foundation_types": technology.get("foundationTypes", []),
            "design_features": technology.get("features", []),
            "resistance_elements": technology.get("resistanceElements", []),

            # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®æ¡ä»¶
            "region_conditions": {
                "snow_region": environment.get("snowRegion", ""),
                "fire_zone": environment.get("fireZone", ""),
            },
            "ground_condition": environment.get("groundCondition", ""),
            "client_name": metadata['clientName'],
            "partners": [metadata['clientName']] if metadata['clientName'] else [],
            "inspection_agency": management.get("inspectionAgency"),

            # ãã®ä»–
            "summary": analysis.get("summary", ""),

            # ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†ç”¨ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰
            "analysis_result": analysis_result,
            "file_id": folder_id,
            "extracted_at": firestore.SERVER_TIMESTAMP,
            "folder_name": folder_name,
            "folder_path": full_path,
            "file_count": {
                "calc": len(calc_files),
                "drawing": len(drawing_files),
                "cert": 1 if cert_file else 0,
                "review": 1 if review_file else 0
            }
        }

        # Firestoreã«ä¿å­˜
        collection_ref = db.collection("Beta_2025_12_24")
        collection_ref.document(doc_id).set(save_data)

        return True, f"æˆåŠŸ: {len(calc_files)}ãƒ•ã‚¡ã‚¤ãƒ«è§£æ"

    except Exception as e:
        return False, f"ã‚¨ãƒ©ãƒ¼: {str(e)[:100]}"

# 8. ä¸¦åˆ—å‡¦ç†å®Ÿè¡Œ
def process_projects_parallel(project_folders: List[Dict], max_workers: int = 5):
    """
    è¤‡æ•°ã®æ¡ˆä»¶ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä¸¦åˆ—å‡¦ç†

    Args:
        project_folders: æ¡ˆä»¶ãƒ•ã‚©ãƒ«ãƒ€æƒ…å ±ã®ãƒªã‚¹ãƒˆ
        max_workers: ä¸¦åˆ—å‡¦ç†æ•°
    """
    print(f"\nğŸš€ ä¸¦åˆ—å‡¦ç†é–‹å§‹: {len(project_folders)}ä»¶ã‚’{max_workers}ä¸¦åˆ—ã§å‡¦ç†")

    # å„ãƒ—ãƒ­ã‚»ã‚¹ã§ä½¿ç”¨ã™ã‚‹ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—
    token = get_access_token()
    if not token:
        print("âŒ èªè¨¼å¤±æ•—")
        return

    success_count = 0
    error_count = 0

    # ProcessPoolExecutorã§ä¸¦åˆ—å‡¦ç†
    with ProcessPoolExecutor(max_workers=max_workers) as executor:
        # ã‚¿ã‚¹ã‚¯ã‚’æŠ•å…¥
        future_to_project = {
            executor.submit(process_single_project, project, token, TARGET_USER_EMAIL): project
            for project in project_folders
        }

        # å®Œäº†ã—ãŸã‚¿ã‚¹ã‚¯ã‹ã‚‰é †ã«å‡¦ç†
        for future in as_completed(future_to_project):
            project = future_to_project[future]
            try:
                success, message = future.result()
                if success:
                    success_count += 1
                    print(f"âœ… [{success_count + error_count}/{len(project_folders)}] {project['name']}: {message}")
                else:
                    error_count += 1
                    print(f"âŒ [{success_count + error_count}/{len(project_folders)}] {project['name']}: {message}")
            except Exception as e:
                error_count += 1
                print(f"âŒ [{success_count + error_count}/{len(project_folders)}] {project['name']}: ä¾‹å¤– - {str(e)[:100]}")

            # å°‘ã—å¾…æ©Ÿï¼ˆãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–ï¼‰
            time.sleep(0.2)

    print(f"\nğŸ“Š å‡¦ç†å®Œäº†: æˆåŠŸ {success_count}ä»¶ / ã‚¨ãƒ©ãƒ¼ {error_count}ä»¶ / åˆè¨ˆ {len(project_folders)}ä»¶")

# 9. ãƒ¡ã‚¤ãƒ³å‡¦ç†
def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    parser = argparse.ArgumentParser(description='Uplan Knowledge Base - Batch Processor (ä¸¦åˆ—å‡¦ç†ç‰ˆ)')
    parser.add_argument('--target-path', type=str, default=DEFAULT_TARGET_PATH,
                       help=f'æŠ½å‡ºå¯¾è±¡ã®ãƒ«ãƒ¼ãƒˆãƒ‘ã‚¹ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {DEFAULT_TARGET_PATH})')
    parser.add_argument('--workers', type=int, default=DEFAULT_MAX_WORKERS,
                       help=f'ä¸¦åˆ—å‡¦ç†æ•° (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {DEFAULT_MAX_WORKERS})')
    parser.add_argument('--mode', choices=['full', 'delta'], default='full',
                       help='å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰: full=å…¨ä»¶ã‚¹ã‚­ãƒ£ãƒ³, delta=å·®åˆ†æ›´æ–°')

    args = parser.parse_args()

    print("=" * 80)
    print("ğŸš€ Uplan Knowledge Base - Batch Processor v3 (ä¸¦åˆ—å‡¦ç†ç‰ˆ)")
    print("=" * 80)
    print(f"ğŸ“‚ ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ‘ã‚¹: {args.target_path}")
    print(f"âš™ï¸  ä¸¦åˆ—å‡¦ç†æ•°: {args.workers}")
    print(f"ğŸ”„ å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰: {args.mode}")
    print("=" * 80)

    # èªè¨¼
    token = get_access_token()
    if not token:
        print("âŒ èªè¨¼å¤±æ•—ã®ãŸã‚çµ‚äº†ã—ã¾ã™")
        return

    if args.mode == 'delta':
        # å·®åˆ†æ›´æ–°ãƒ¢ãƒ¼ãƒ‰
        print("\nğŸ“Š å·®åˆ†æ›´æ–°ãƒ¢ãƒ¼ãƒ‰: å‰å›ã‹ã‚‰ã®å¤‰æ›´ã®ã¿ã‚’å‡¦ç†ã—ã¾ã™")
        system_config = get_system_config()
        delta_link = system_config.get('deltaLink') if system_config else None

        if not delta_link:
            print("âš ï¸ ãƒ‡ãƒ«ã‚¿ãƒªãƒ³ã‚¯ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å…¨ä»¶ã‚¹ã‚­ãƒ£ãƒ³ãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
            return

        changed_items, new_delta_link = fetch_drive_changes(token, TARGET_USER_EMAIL, delta_link)

        if not changed_items:
            print("âœ¨ å¤‰æ›´ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            return

        # å¤‰æ›´ã•ã‚ŒãŸãƒ•ã‚©ãƒ«ãƒ€ã‚’å‡¦ç†ï¼ˆã“ã“ã§ã¯ç°¡ç•¥åŒ–ã®ãŸã‚çœç•¥ï¼‰
        print(f"ğŸ“ {len(changed_items)}ä»¶ã®å¤‰æ›´ã‚’æ¤œå‡ºã—ã¾ã—ãŸ")
        # TODO: å·®åˆ†ãƒ¢ãƒ¼ãƒ‰ã®è©³ç´°å®Ÿè£…

    else:
        # å…¨ä»¶ã‚¹ã‚­ãƒ£ãƒ³ãƒ¢ãƒ¼ãƒ‰
        print("\nğŸ“Š å…¨ä»¶ã‚¹ã‚­ãƒ£ãƒ³ãƒ¢ãƒ¼ãƒ‰: ã™ã¹ã¦ã®ãƒ•ã‚©ãƒ«ãƒ€ã‚’æ¢ç´¢ã—ã¾ã™")

        # ãƒ•ã‚©ãƒ«ãƒ€åé›†
        project_folders = collect_all_project_folders(token, TARGET_USER_EMAIL, args.target_path)

        if not project_folders:
            print("âš ï¸ æ¡ˆä»¶ãƒ•ã‚©ãƒ«ãƒ€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            return

        # ä¸¦åˆ—å‡¦ç†
        process_projects_parallel(project_folders, max_workers=args.workers)

        # ãƒ‡ãƒ«ã‚¿ãƒªãƒ³ã‚¯å–å¾—ã¨ä¿å­˜
        print("\nğŸ“ åˆå›ãƒ‡ãƒ«ã‚¿ãƒªãƒ³ã‚¯ã‚’å–å¾—ä¸­...")
        _, new_delta_link = fetch_drive_changes(token, TARGET_USER_EMAIL, None)
        if new_delta_link:
            save_system_config(new_delta_link)

    print("\nğŸ‰ å…¨å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸ")

if __name__ == "__main__":
    main()
