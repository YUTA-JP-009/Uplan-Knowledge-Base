"""
OneDriveæ¤œç´¢ã§æ¡ˆä»¶ã‚’è¦‹ã¤ã‘ã¦ç›´æ¥å‡¦ç†ã™ã‚‹
"""

import msal
import requests
import json
import os
import gc
import time
from datetime import datetime
from typing import List, Dict, Tuple, Optional
import vertexai
from vertexai.generative_models import GenerativeModel, Part, GenerationConfig
from google.cloud import secretmanager
from google.cloud import firestore
from google.api_core import retry, exceptions
import re

# --- è¨­å®š ---
GCP_PROJECT_ID = "uplan-knowledge-base"
LOCATION = "us-central1"
TARGET_USER_EMAIL = "info@uplan2018.onmicrosoft.com"

# ãƒ†ã‚¹ãƒˆã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³
TEST_COLLECTION = "Projects_Test_20260108_182447"

# æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
SEARCH_KEYWORDS = [
    "ä¸‰ç”°2ä¸ç›®",
    "å°ã•ãªãŠè‘¬å¼"
]

# ---------------------------------------------------------

def get_secret(secret_id):
    """Secret Managerã‹ã‚‰ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã‚’å–å¾—"""
    client = secretmanager.SecretManagerServiceClient()
    name = f"projects/{GCP_PROJECT_ID}/secrets/{secret_id}/versions/latest"
    response = client.access_secret_version(request={"name": name})
    return response.payload.data.decode("UTF-8")

def get_access_token():
    """Microsoft Graph APIç”¨ã®ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—"""
    try:
        client_id = get_secret("MS_CLIENT_ID")
        tenant_id = get_secret("MS_TENANT_ID")
        client_secret = get_secret("MS_CLIENT_SECRET")

        authority = f"https://login.microsoftonline.com/{tenant_id}"
        app = msal.ConfidentialClientApplication(client_id, authority=authority, client_credential=client_secret)
        result = app.acquire_token_for_client(scopes=["https://graph.microsoft.com/.default"])
        return result.get("access_token")
    except Exception as e:
        print(f"âŒ èªè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
        return None

def search_folders_by_keyword(access_token, keyword):
    """Microsoft Graph APIã§ãƒ•ã‚©ãƒ«ãƒ€ã‚’æ¤œç´¢"""
    headers = {"Authorization": f"Bearer {access_token}"}

    print(f"\nğŸ” æ¤œç´¢ä¸­: {keyword}")

    search_url = f"https://graph.microsoft.com/v1.0/users/{TARGET_USER_EMAIL}/drive/root/search(q='{keyword}')"

    try:
        response = requests.get(search_url, headers=headers, timeout=30)
        response.raise_for_status()
        results = response.json().get('value', [])

        # æ§‹é€ è¨­è¨ˆå›³æ›¸ãƒ•ã‚©ãƒ«ãƒ€ã‚’æ¢ã™
        target_folders = []
        for item in results:
            if 'folder' in item:
                name = item.get('name', '')
                parent_path = item.get('parentReference', {}).get('path', '')

                # æ§‹é€ è¨­è¨ˆå›³æ›¸ãƒ•ã‚©ãƒ«ãƒ€ã‚’å„ªå…ˆ
                if ('æ§‹é€ è¨­è¨ˆå›³æ›¸' in name or 'æ§‹é€ è¨ˆç®—æ›¸' in name) and 'â—‹' not in name:
                    if '/drive/root:' in parent_path:
                        parent_path = parent_path.replace('/drive/root:', '')
                    full_path = f"{parent_path}/{name}".lstrip('/')
                    target_folders.append({
                        'id': item['id'],
                        'name': name,
                        'path': full_path,
                        'webUrl': item.get('webUrl', '')
                    })

        if target_folders:
            print(f"âœ… {len(target_folders)}ä»¶ã®ãƒ•ã‚©ãƒ«ãƒ€ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
            for folder in target_folders[:3]:  # æœ€åˆã®3ä»¶ã‚’è¡¨ç¤º
                print(f"   ğŸ“‚ {folder['path']}")
            return target_folders
        else:
            print(f"âš ï¸ ãƒ•ã‚©ãƒ«ãƒ€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            return []

    except Exception as e:
        print(f"âŒ æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
        return []

def extract_project_metadata(folder_path):
    """ãƒ•ã‚©ãƒ«ãƒ€ãƒ‘ã‚¹ã‹ã‚‰æ¡ˆä»¶ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º"""
    metadata = {
        "structureType": None,
        "clientName": None,
        "projectName": None
    }

    parts = folder_path.split('/')

    for i, part in enumerate(parts):
        if 'æœ¨é€ ' in part:
            metadata["structureType"] = "æœ¨é€ "
            if i + 2 < len(parts):
                client_folder = parts[i + 2]
                match = re.match(r'^[AT]\d+_?(.+?)(?:ï¼ˆ.+?ï¼‰)?$', client_folder)
                if match:
                    metadata["clientName"] = match.group(1).strip()
                    break
                match2 = re.match(r'^\d+\s+(.+)$', client_folder)
                if match2:
                    metadata["clientName"] = match2.group(1).strip()
                    break
        elif 'RC' in part or 'é‰„ç­‹ã‚³ãƒ³ã‚¯ãƒªãƒ¼ãƒˆ' in part:
            metadata["structureType"] = "RCé€ "
        elif 'é‰„éª¨' in part:
            metadata["structureType"] = "Sé€ "

    for part in parts:
        if part.startswith(('2024', '2025', '2026')):
            project_part = part.split('ï¼')[0]
            match = re.match(r'^\d+_(.+)$', project_part)
            if match:
                metadata["projectName"] = match.group(1).strip()
                break

    return metadata

def select_project_files(file_list):
    """ãƒ•ã‚©ãƒ«ãƒ€å†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã€æ§‹é€ è¨ˆç®—æ›¸ãƒ»å›³é¢ãƒ»è¨¼æ˜æ›¸ãƒ»å¯©æŸ»è¡¨ã‚’é¸å®š"""
    all_calc_files = []
    all_drawing_files = []
    safety_certs = []
    review_sheets = []

    for item in file_list:
        if "folder" in item:
            continue

        name = item.get("name", "")
        name_lower = name.lower()

        if not name_lower.endswith(".pdf"):
            continue

        if "æ§‹é€ è¨ˆç®—æ›¸" in name or "è¨ˆç®—æ›¸" in name:
            all_calc_files.append(item)
        elif "æ§‹é€ å›³" in name or "ä¼å›³" in name or "è»¸çµ„å›³" in name:
            all_drawing_files.append(item)
        elif "å®‰å…¨è¨¼æ˜" in name or "é©åˆè¨¼æ˜" in name:
            safety_certs.append(item)
        elif "å¯©æŸ»è¡¨" in name or "ãƒã‚§ãƒƒã‚¯ã‚·ãƒ¼ãƒˆ" in name:
            review_sheets.append(item)

    best_cert = safety_certs[-1] if safety_certs else None
    best_review = review_sheets[-1] if review_sheets else None

    return all_calc_files, all_drawing_files, best_cert, best_review

@retry.Retry(
    predicate=retry.if_exception_type(exceptions.ResourceExhausted),
    initial=1.0,
    maximum=60.0,
    multiplier=2.0,
    timeout=300.0
)
def analyze_with_gemini_retry(file_data_list, file_name_hints=None):
    """Gemini APIã‚’å‘¼ã³å‡ºã—ï¼ˆ429ã‚¨ãƒ©ãƒ¼æ™‚ã¯è‡ªå‹•ãƒªãƒˆãƒ©ã‚¤ï¼‰"""
    return analyze_with_gemini(file_data_list, file_name_hints)

def analyze_with_gemini(file_data_list, file_name_hints=None):
    """Gemini 2.0 Flash (Vertex AI) ã§PDFã‚’è§£æ"""
    vertexai.init(project=GCP_PROJECT_ID, location=LOCATION)
    model = GenerativeModel("gemini-2.0-flash-exp")

    parts = []

    if file_name_hints:
        hint_text = "ã€ãƒ•ã‚¡ã‚¤ãƒ«åãƒ’ãƒ³ãƒˆã€‘\n" + "\n".join([f"- {hint}" for hint in file_name_hints])
        parts.append(hint_text)

    for file_info in file_data_list:
        parts.append(Part.from_data(file_info["data"], mime_type=file_info["mime_type"]))
        parts.append(f"[ãƒ•ã‚¡ã‚¤ãƒ«å: {file_info['name']}]")

    prompt = """
ä»¥ä¸‹ã®æ§‹é€ è¨ˆç®—æ›¸PDFã‚’è§£æã—ã€JSONå½¢å¼ã§æƒ…å ±ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚

ã€æŠ½å‡ºé …ç›®ã€‘
1. éƒ½é“åºœçœŒåï¼ˆprefectureï¼‰
2. æ§‹é€ ç¨®åˆ¥ï¼ˆstructureTypesï¼‰: ["æœ¨é€ ", "RCé€ ", "Sé€ ", "æ··æ§‹é€ "]
3. ç”¨é€”ç¨®åˆ¥ï¼ˆuseTypesï¼‰: ["å…±åŒä½å®…", "äº‹å‹™æ‰€", "åº—èˆ—", "æˆ¸å»ºä½å®…", etc.]
4. éšæ•°ã‚«ãƒ†ã‚´ãƒªï¼ˆfloorCategoriesï¼‰: ["å¹³å±‹", "2éšå»ºã¦", "3éšå»ºã¦ä»¥ä¸Š"]
5. å»¶ã¹é¢ç©ï¼ˆtotalAreaï¼‰: æ•°å€¤
6. é¢ç©ã‚«ãƒ†ã‚´ãƒªï¼ˆareaCategoryï¼‰: "500ã¡æœªæº€" | "500ã¡ä»¥ä¸Š"
7. æ€§èƒ½è¡¨ç¤ºï¼ˆperformanceLabelsï¼‰: ["è€éœ‡ç­‰ç´š3", "åˆ¶æŒ¯æ§‹é€ ", etc.]
8. è¨ˆç®—ãƒ«ãƒ¼ãƒˆï¼ˆcalcRoutesï¼‰: ["ãƒ«ãƒ¼ãƒˆ1", "ãƒ«ãƒ¼ãƒˆ2", "ãƒ«ãƒ¼ãƒˆ3", "è¨±å®¹å¿œåŠ›åº¦è¨ˆç®—", "é™ç•Œè€åŠ›è¨ˆç®—"]
9. åŸºç¤å½¢å¼ï¼ˆfoundationTypesï¼‰: ["ã¹ãŸåŸºç¤", "å¸ƒåŸºç¤", "æ­åŸºç¤"]
10. è¨­è¨ˆç‰¹è¨˜ï¼ˆfeaturesï¼‰: ["é‰„éª¨é€ å¤–éƒ¨éšæ®µ", "å¹æŠœã‘", "ã‚ªãƒ¼ãƒãƒ¼ãƒãƒ³ã‚°", etc.]
11. è€åŠ›è¦ç´ ï¼ˆresistanceElementsï¼‰: ["ç­‹ã‹ã„", "æ§‹é€ ç”¨åˆæ¿", "è€åŠ›å£", etc.]
12. ç©é›ªåœ°åŸŸï¼ˆsnowRegionï¼‰: "ä¸€èˆ¬åœ°åŸŸ" | "å¤šé›ªåœ°åŸŸ"
13. é˜²ç«åœ°åŸŸï¼ˆfireZoneï¼‰: "æŒ‡å®šãªã—" | "æº–é˜²ç«åœ°åŸŸ" | "é˜²ç«åœ°åŸŸ"
14. åœ°ç›¤ç¨®åˆ¥ï¼ˆgroundConditionï¼‰: "æ™®é€šåœ°ç›¤" | "è»Ÿå¼±åœ°ç›¤"
15. è¨ˆç®—ã‚½ãƒ•ãƒˆï¼ˆsoftwareï¼‰
16. æ¤œæŸ»æ©Ÿé–¢ï¼ˆinspectionAgencyï¼‰
17. ã‚µãƒãƒªãƒ¼ï¼ˆsummaryï¼‰: æ¡ˆä»¶ã®ç‰¹å¾´ã‚’2-3æ–‡ã§è¦ç´„

ã€å‡ºåŠ›å½¢å¼ã€‘
```json
{
  "basic": {
    "prefecture": "ç¥å¥ˆå·çœŒ",
    "structureTypes": ["æœ¨é€ "],
    "useTypes": ["å…±åŒä½å®…"],
    "floorCategories": ["3éšå»ºã¦ä»¥ä¸Š"],
    "totalArea": 850.5,
    "areaCategory": "500ã¡ä»¥ä¸Š"
  },
  "regulations": {
    "performanceLabels": ["è€éœ‡ç­‰ç´š3"],
    "calcRoutes": ["è¨±å®¹å¿œåŠ›åº¦è¨ˆç®—"],
    "calcRouteReasoning": "..."
  },
  "technology": {
    "foundationTypes": ["ã¹ãŸåŸºç¤"],
    "features": ["é‰„éª¨é€ å¤–éƒ¨éšæ®µ"],
    "resistanceElements": ["æ§‹é€ ç”¨åˆæ¿"]
  },
  "environment": {
    "snowRegion": "ä¸€èˆ¬åœ°åŸŸ",
    "fireZone": "æº–é˜²ç«åœ°åŸŸ",
    "groundCondition": "æ™®é€šåœ°ç›¤"
  },
  "management": {
    "software": "STRDESIGN Ver.17-03",
    "inspectionAgency": "æ—¥æœ¬ERI"
  },
  "analysis": {
    "summary": "..."
  }
}
```

ãã‚Œã§ã¯è§£æã‚’é–‹å§‹ã—ã¦ãã ã•ã„ã€‚
"""

    parts.insert(0, prompt)

    try:
        response = model.generate_content(
            parts,
            generation_config=GenerationConfig(
                temperature=0.1,
                top_p=0.95,
                max_output_tokens=8192,
            )
        )

        text = response.text

        if "```json" in text:
            json_str = text.split("```json")[1].split("```")[0].strip()
        elif "```" in text:
            json_str = text.split("```")[1].split("```")[0].strip()
        else:
            json_str = text.strip()

        result = json.loads(json_str)
        return result

    except Exception as e:
        print(f"âŒ Geminiè§£æã‚¨ãƒ©ãƒ¼: {e}")
        return None

def process_folder(folder_info: Dict, access_token: str, user_email: str) -> Tuple[bool, str, float]:
    """
    ãƒ•ã‚©ãƒ«ãƒ€ã‚’å‡¦ç†
    """
    start_time = time.time()

    headers = {"Authorization": f"Bearer {access_token}"}
    folder_id = folder_info['id']
    folder_name = folder_info['name']
    folder_path = folder_info['path']
    folder_web_url = folder_info['webUrl']

    try:
        print(f"\nğŸ“‚ å‡¦ç†é–‹å§‹: {folder_name}")
        print(f"   ãƒ‘ã‚¹: {folder_path}")

        # ãƒ•ã‚©ãƒ«ãƒ€å†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—
        folder_url = f"https://graph.microsoft.com/v1.0/users/{user_email}/drive/items/{folder_id}/children"
        response = requests.get(folder_url, headers=headers, timeout=60)
        response.raise_for_status()
        items = response.json().get('value', [])

        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸å®š
        calc_files, drawing_files, cert_file, review_file = select_project_files(items)

        if not calc_files:
            elapsed = time.time() - start_time
            return False, "æ§‹é€ è¨ˆç®—æ›¸PDFãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“", elapsed

        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåã‚’æŠ½å‡º
        metadata = extract_project_metadata(folder_path)
        project_name = metadata.get('projectName') or folder_name

        # PDFã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        file_data_list = []
        file_name_hints = []

        print(f"   ğŸ“¥ PDFãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­: {len(calc_files)}ãƒ•ã‚¡ã‚¤ãƒ«")
        for pdf_file in calc_files[:5]:
            download_url = pdf_file.get('@microsoft.graph.downloadUrl')
            if download_url:
                pdf_response = requests.get(download_url, timeout=120)
                if pdf_response.status_code == 200:
                    file_data_list.append({
                        "data": pdf_response.content,
                        "mime_type": "application/pdf",
                        "name": pdf_file['name']
                    })
                    file_name_hints.append(pdf_file['name'])

        if not file_data_list:
            elapsed = time.time() - start_time
            return False, "PDFãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•—", elapsed

        # Gemini APIã§è§£æ
        print(f"   ğŸ¤– AIè§£æä¸­...")
        analysis_result = analyze_with_gemini_retry(file_data_list, file_name_hints)

        del file_data_list
        gc.collect()

        if not analysis_result:
            elapsed = time.time() - start_time
            return False, "AIè§£æå¤±æ•—", elapsed

        # Firestoreã«ä¿å­˜
        db = firestore.Client(project=GCP_PROJECT_ID, database="uplan")

        timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
        safe_project_name = (project_name or "ä¸æ˜ç‰©ä»¶").replace("/", "-").replace(":", "-")
        doc_id = f"{safe_project_name}_{timestamp}"

        basic = analysis_result.get("basic", {})
        regulations = analysis_result.get("regulations", {})
        technology = analysis_result.get("technology", {})
        environment = analysis_result.get("environment", {})
        management = analysis_result.get("management", {})
        analysis = analysis_result.get("analysis", {})

        # ä½œæˆå¹´æœˆã®æŠ½å‡º
        created_year_month = None
        date_match = re.match(r'^(\d{4})(\d{2})\d{2}', folder_name)
        if date_match:
            year = date_match.group(1)
            month = date_match.group(2).lstrip('0')
            created_year_month = f"{year}å¹´{month}æœˆ"

        save_data = {
            "prefecture": basic.get("prefecture"),
            "structure_types": basic.get("structureTypes", []),
            "use_types": basic.get("useTypes", []),
            "floor_categories": basic.get("floorCategories", []),
            "total_area": basic.get("totalArea", 0.0),
            "area_category": basic.get("areaCategory", ""),
            "performance_requirements": regulations.get("performanceLabels", []),
            "calc_routes": regulations.get("calcRoutes", []),
            "calc_route_reasoning": regulations.get("calcRouteReasoning", ""),
            "foundation_types": technology.get("foundationTypes", []),
            "design_features": technology.get("features", []),
            "resistance_elements": technology.get("resistanceElements", []),
            "region_conditions": {
                "snow_region": environment.get("snowRegion", ""),
                "fire_zone": environment.get("fireZone", ""),
            },
            "ground_condition": environment.get("groundCondition", ""),
            "client_name": metadata['clientName'],
            "partners": [metadata['clientName']] if metadata['clientName'] else [],
            "inspection_agency": management.get("inspectionAgency"),
            "summary": analysis.get("summary", ""),
            "analysis_result": analysis_result,
            "file_id": folder_id,
            "extracted_at": firestore.SERVER_TIMESTAMP,
            "created_year_month": created_year_month,
            "project_name": project_name,
            "folder_name": folder_name,
            "folder_path": folder_path,
            "folder_url": folder_web_url,
            "file_count": {
                "calc": len(calc_files),
                "drawing": len(drawing_files),
                "cert": 1 if cert_file else 0,
                "review": 1 if review_file else 0
            }
        }

        print(f"   ğŸ’¾ Firestoreä¿å­˜ä¸­...")
        collection_ref = db.collection(TEST_COLLECTION)
        collection_ref.document(doc_id).set(save_data)

        elapsed = time.time() - start_time
        return True, f"æˆåŠŸ: {len(calc_files)}ãƒ•ã‚¡ã‚¤ãƒ«è§£æ", elapsed

    except Exception as e:
        elapsed = time.time() - start_time
        return False, f"ã‚¨ãƒ©ãƒ¼: {str(e)[:100]}", elapsed

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("=" * 80)
    print("ğŸ” OneDriveæ¤œç´¢ & ç›´æ¥å‡¦ç†")
    print("=" * 80)
    print(f"ğŸ“Š ä¿å­˜å…ˆã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³: {TEST_COLLECTION}")
    print("=" * 80)

    overall_start = time.time()

    # èªè¨¼
    token = get_access_token()
    if not token:
        print("âŒ èªè¨¼å¤±æ•—ã®ãŸã‚çµ‚äº†ã—ã¾ã™")
        return

    all_target_folders = []

    # å„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§æ¤œç´¢
    for keyword in SEARCH_KEYWORDS:
        folders = search_folders_by_keyword(token, keyword)
        if folders:
            # æœ€ã‚‚é–¢é€£æ€§ã®é«˜ã„ã‚‚ã®ã‚’é¸æŠï¼ˆæœ€åˆã®1ä»¶ï¼‰
            all_target_folders.append(folders[0])

    if not all_target_folders:
        print("\nâŒ å¯¾è±¡ãƒ•ã‚©ãƒ«ãƒ€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        return

    print(f"\nğŸ“‚ å‡¦ç†å¯¾è±¡: {len(all_target_folders)}ä»¶")

    results = []

    # å„ãƒ•ã‚©ãƒ«ãƒ€ã‚’å‡¦ç†
    for i, folder_info in enumerate(all_target_folders, 1):
        print(f"\n[{i}/{len(all_target_folders)}] {folder_info['name']}")

        # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–
        if i > 1:
            print("   â³ ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–ã®ãŸã‚60ç§’å¾…æ©Ÿ...")
            time.sleep(60)

        success, message, elapsed = process_folder(folder_info, token, TARGET_USER_EMAIL)

        results.append({
            "folder": folder_info['name'],
            "path": folder_info['path'],
            "success": success,
            "message": message,
            "elapsed": elapsed
        })

        if success:
            print(f"   âœ… {message} (å‡¦ç†æ™‚é–“: {elapsed:.1f}ç§’)")
        else:
            print(f"   âŒ {message} (å‡¦ç†æ™‚é–“: {elapsed:.1f}ç§’)")

    overall_elapsed = time.time() - overall_start

    # çµæœã‚µãƒãƒªãƒ¼
    print("\n" + "=" * 80)
    print("ğŸ“Š å‡¦ç†çµæœã‚µãƒãƒªãƒ¼")
    print("=" * 80)

    success_count = sum(1 for r in results if r["success"])
    total_processing_time = sum(r["elapsed"] for r in results)
    avg_time = total_processing_time / len(results) if results else 0

    print(f"âœ… æˆåŠŸ: {success_count}/{len(results)}ä»¶")
    print(f"âŒ å¤±æ•—: {len(results) - success_count}/{len(results)}ä»¶")
    print(f"â±ï¸  ç·å®Ÿè¡Œæ™‚é–“: {overall_elapsed:.1f}ç§’ ({overall_elapsed/60:.1f}åˆ†)")
    print(f"â±ï¸  å¹³å‡å‡¦ç†æ™‚é–“: {avg_time:.1f}ç§’/ä»¶")
    print(f"ğŸ’¾ ä¿å­˜å…ˆ: Firestore > {TEST_COLLECTION}")
    print("=" * 80)

    # è©³ç´°çµæœ
    print("\nğŸ“‹ è©³ç´°çµæœ:")
    for i, result in enumerate(results, 1):
        status = "âœ…" if result["success"] else "âŒ"
        print(f"{i}. {status} {result['folder']}")
        print(f"   ãƒ‘ã‚¹: {result['path']}")
        print(f"   çµæœ: {result['message']} ({result['elapsed']:.1f}ç§’)")

if __name__ == "__main__":
    main()
