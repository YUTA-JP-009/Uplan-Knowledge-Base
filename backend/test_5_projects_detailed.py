"""
5ç‰©ä»¶ã®è©³ç´°æŠ½å‡ºãƒ†ã‚¹ãƒˆ
ä¸å¯§ã«æ™‚é–“ã‚’ã‹ã‘ã¦ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œã™ã‚‹
"""

import msal
import requests
import json
import os
import time
import random
from typing import List, Dict, Tuple, Optional
import vertexai
from vertexai.generative_models import GenerativeModel, Part, GenerationConfig
from google.cloud import secretmanager
from google.cloud import firestore
from datetime import datetime, timezone, timedelta
import re

# æ—¥æœ¬æ™‚é–“ã®ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³
JST = timezone(timedelta(hours=9))

# --- è¨­å®š ---
GCP_PROJECT_ID = "uplan-knowledge-base"
LOCATION = "us-central1"
TARGET_USER_EMAIL = "info@uplan2018.onmicrosoft.com"

# ãƒ†ã‚¹ãƒˆå¯¾è±¡ã®5ç‰©ä»¶
TEST_PROJECTS = [
    {
        "name": "æ¾ä¸‹é‚¸",
        "folder_path": "01.æœ¨é€ ï¼ˆåœ¨æ¥è»¸çµ„ï¼‰/â–¡ãŸè¡Œ/A00790_å¤šç”°å»ºç¯‰è¨­è¨ˆäº‹å‹™æ‰€/2025001_æ¾ä¸‹é‚¸/09.æˆæœç‰©/20250911_ã€è£œæ­£ã€‘æ¾ä¸‹é‚¸_æ§‹é€ è¨­è¨ˆå›³æ›¸ä¸€å¼",
        "url": "https://uplan2018-my.sharepoint.com/personal/info_uplan2018_onmicrosoft_com/Documents/001_ï¼µ'plan_å…¨ç¤¾/01.æ§‹é€ è¨­è¨ˆ/01.æœ¨é€ ï¼ˆåœ¨æ¥è»¸çµ„ï¼‰/â–¡ãŸè¡Œ/A00790_å¤šç”°å»ºç¯‰è¨­è¨ˆäº‹å‹™æ‰€/2025001_æ¾ä¸‹é‚¸/09.æˆæœç‰©/20250911_ã€è£œæ­£ã€‘æ¾ä¸‹é‚¸_æ§‹é€ è¨­è¨ˆå›³æ›¸ä¸€å¼"
    },
    {
        "name": "ãƒ•ãƒ«ã‚¤ãƒæ§˜ã‚ªãƒ•ã‚£ã‚¹æ–°ç¯‰å·¥äº‹",
        "folder_path": "01.æœ¨é€ ï¼ˆåœ¨æ¥è»¸çµ„ï¼‰/â–¡ï¼¡è¡Œ/453 Luceå»ºç¯‰è¨­è¨ˆäº‹å‹™æ‰€/2025003_ãƒ•ãƒ«ã‚¤ãƒæ§˜ã‚ªãƒ•ã‚£ã‚¹æ–°ç¯‰å·¥äº‹/09.æˆæœç‰©/20251111_ã€äº‹å‰ã€‘ãƒ•ãƒ«ã‚¤ãƒæ§˜ã‚ªãƒ•ã‚£ã‚¹æ–°ç¯‰å·¥äº‹_æ§‹é€ è¨­è¨ˆå›³æ›¸ä¸€å¼",
        "url": "https://uplan2018-my.sharepoint.com/personal/info_uplan2018_onmicrosoft_com/Documents/001_ï¼µ'plan_å…¨ç¤¾/01.æ§‹é€ è¨­è¨ˆ/01.æœ¨é€ ï¼ˆåœ¨æ¥è»¸çµ„ï¼‰/â–¡ï¼¡è¡Œ/453 Luceå»ºç¯‰è¨­è¨ˆäº‹å‹™æ‰€/2025003_ãƒ•ãƒ«ã‚¤ãƒæ§˜ã‚ªãƒ•ã‚£ã‚¹æ–°ç¯‰å·¥äº‹/09.æˆæœç‰©/20251111_ã€äº‹å‰ã€‘ãƒ•ãƒ«ã‚¤ãƒæ§˜ã‚ªãƒ•ã‚£ã‚¹æ–°ç¯‰å·¥äº‹_æ§‹é€ è¨­è¨ˆå›³æ›¸ä¸€å¼"
    },
    {
        "name": "è±Šä¸­ã®è²¸å€‰åº«å…¼ã‚ªãƒ•ã‚£ã‚¹",
        "folder_path": "01.æœ¨é€ ï¼ˆåœ¨æ¥è»¸çµ„ï¼‰/â–¡ï¼¡è¡Œ/329 PROCESS5 DESIGN/è±Šä¸­ã®è²¸å€‰åº«å…¼ã‚ªãƒ•ã‚£ã‚¹/09.æˆæœç‰©/20251202_TOYONAKA_BASE_æœ€çµ‚æ§‹é€ è¨­è¨ˆå›³æ›¸ä¸€å¼",
        "url": "https://uplan2018-my.sharepoint.com/personal/info_uplan2018_onmicrosoft_com/Documents/001_ï¼µ'plan_å…¨ç¤¾/01.æ§‹é€ è¨­è¨ˆ/01.æœ¨é€ ï¼ˆåœ¨æ¥è»¸çµ„ï¼‰/â–¡ï¼¡è¡Œ/329 PROCESS5 DESIGN/è±Šä¸­ã®è²¸å€‰åº«å…¼ã‚ªãƒ•ã‚£ã‚¹/09.æˆæœç‰©/20251202_TOYONAKA_BASE_æœ€çµ‚æ§‹é€ è¨­è¨ˆå›³æ›¸ä¸€å¼"
    },
    {
        "name": "ï¼ˆä»®ç§°ï¼‰ä¸‰ç”°2ä¸ç›®AP",
        "folder_path": "01.æœ¨é€ ï¼ˆåœ¨æ¥è»¸çµ„ï¼‰/â–¡ã‚è¡Œ/A00698ã‚¢ã‚¼ãƒªã‚¢ãƒ›ãƒ¼ãƒ /2024009_ï¼ˆä»®ç§°ï¼‰ä¸‰ç”°2ä¸ç›®APï¼2024010_è¨­è¨ˆå¤‰æ›´/09.æˆæœç‰©/20240912_(ä»®ç§°)ä¸‰ç”°2ä¸ç›®AP_æ§‹é€ è¨ˆç®—æ›¸é¡ä¸€å¼",
        "url": "https://uplan2018-my.sharepoint.com/personal/info_uplan2018_onmicrosoft_com/Documents/001_ï¼µ'plan_å…¨ç¤¾/01.æ§‹é€ è¨­è¨ˆ/01.æœ¨é€ ï¼ˆåœ¨æ¥è»¸çµ„ï¼‰/â–¡ã‚è¡Œ/A00698ã‚¢ã‚¼ãƒªã‚¢ãƒ›ãƒ¼ãƒ /2024009_ï¼ˆä»®ç§°ï¼‰ä¸‰ç”°2ä¸ç›®APï¼2024010_è¨­è¨ˆå¤‰æ›´/09.æˆæœç‰©/20240912_(ä»®ç§°)ä¸‰ç”°2ä¸ç›®AP_æ§‹é€ è¨ˆç®—æ›¸é¡ä¸€å¼"
    },
    {
        "name": "ï¼ˆä»®ç§°ï¼‰å°ã•ãªãŠè‘¬å¼ åå¤å±‹æ˜­å’ŒåŒºãƒ›ãƒ¼ãƒ«",
        "folder_path": "01.æœ¨é€ ï¼ˆåœ¨æ¥è»¸çµ„ï¼‰/â–¡ï¼¡è¡Œ/279 A1ãƒ»IDè¨­è¨ˆ/2025012_ï¼ˆä»®ç§°ï¼‰å°ã•ãªãŠè‘¬å¼ åå¤å±‹æ˜­å’ŒåŒºãƒ›ãƒ¼ãƒ«/09.æˆæœç‰©/ç´å“æ™‚/20251128_ã€äº‹å‰ã€‘ï¼ˆä»®ç§°ï¼‰å°ã•ãªãŠè‘¬å¼ åå¤å±‹æ˜­å’ŒåŒºãƒ›ãƒ¼ãƒ«_æ§‹é€ è¨­è¨ˆå›³æ›¸ä¸€å¼",
        "url": "https://uplan2018-my.sharepoint.com/personal/info_uplan2018_onmicrosoft_com/Documents/001_ï¼µ'plan_å…¨ç¤¾/01.æ§‹é€ è¨­è¨ˆ/01.æœ¨é€ ï¼ˆåœ¨æ¥è»¸çµ„ï¼‰/â–¡ï¼¡è¡Œ/279 A1ãƒ»IDè¨­è¨ˆ/2025012_ï¼ˆä»®ç§°ï¼‰å°ã•ãªãŠè‘¬å¼ åå¤å±‹æ˜­å’ŒåŒºãƒ›ãƒ¼ãƒ«/09.æˆæœç‰©/ç´å“æ™‚/20251128_ã€äº‹å‰ã€‘ï¼ˆä»®ç§°ï¼‰å°ã•ãªãŠè‘¬å¼ åå¤å±‹æ˜­å’ŒåŒºãƒ›ãƒ¼ãƒ«_æ§‹é€ è¨­è¨ˆå›³æ›¸ä¸€å¼"
    }
]

# ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–è¨­å®š
INITIAL_RETRY_DELAY = 3.0  # ãƒ†ã‚¹ãƒˆç”¨ã«å°‘ã—é•·ã‚ã«è¨­å®š
MAX_RETRY_DELAY = 120.0
MAX_RETRIES = 5
JITTER_RANGE = 1.0

# ---------------------------------------------------------

def get_secret(secret_id):
    """Secret Managerã‹ã‚‰ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã‚’å–å¾—"""
    client = secretmanager.SecretManagerServiceClient()
    name = f"projects/{GCP_PROJECT_ID}/secrets/{secret_id}/versions/latest"
    response = client.access_secret_version(request={"name": name})
    return response.payload.data.decode("UTF-8")

def get_access_token():
    """Microsoft Graph APIç”¨ã®ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—"""
    try:
        client_id = get_secret("MS_CLIENT_ID")
        tenant_id = get_secret("MS_TENANT_ID")
        client_secret = get_secret("MS_CLIENT_SECRET")

        authority = f"https://login.microsoftonline.com/{tenant_id}"
        app = msal.ConfidentialClientApplication(client_id, authority=authority, client_credential=client_secret)
        result = app.acquire_token_for_client(scopes=["https://graph.microsoft.com/.default"])
        return result.get("access_token")
    except Exception as e:
        print(f"âŒ èªè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
        return None

def extract_project_metadata(folder_path):
    """ãƒ•ã‚©ãƒ«ãƒ€ãƒ‘ã‚¹ã‹ã‚‰æ¡ˆä»¶ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º"""
    metadata = {
        "structureType": None,
        "clientName": None,
        "projectName": None,
        "createdDate": None
    }

    parts = folder_path.split('/')

    # æ§‹é€ ç¨®åˆ¥ã¨ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåã®æŠ½å‡º
    for i, part in enumerate(parts):
        if 'æœ¨é€ ' in part:
            metadata["structureType"] = "æœ¨é€ "
            if i + 2 < len(parts):
                client_folder = parts[i + 2]
                match = re.match(r'^[AT]\d+_?(.+?)(?:ï¼ˆ.+?ï¼‰)?$', client_folder)
                if match:
                    metadata["clientName"] = match.group(1).strip()
                    continue
                match2 = re.match(r'^\d+\s+(.+)$', client_folder)
                if match2:
                    metadata["clientName"] = match2.group(1).strip()
                    continue
        elif 'RC' in part or 'é‰„ç­‹ã‚³ãƒ³ã‚¯ãƒªãƒ¼ãƒˆ' in part:
            metadata["structureType"] = "RCé€ "
        elif 'é‰„éª¨' in part:
            metadata["structureType"] = "Sé€ "

    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåã¨ä½œæˆæ—¥ã®æŠ½å‡º
    for part in parts:
        if part.startswith(('2024', '2025', '2026')):
            match = re.match(r'^(\d{7})_(.+)$', part)
            if match:
                metadata["projectName"] = match.group(2).strip()
                continue

        # ä½œæˆæ—¥ã®æŠ½å‡ºï¼ˆYYYYMMDDãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
        date_match = re.match(r'^(\d{8})_', part)
        if date_match:
            metadata["createdDate"] = date_match.group(1)

    return metadata

def get_folder_id_from_url(access_token, folder_url):
    """SharePointãƒ•ã‚©ãƒ«ãƒ€URLã‹ã‚‰ãƒ•ã‚©ãƒ«ãƒ€IDã‚’å–å¾—"""
    try:
        # URLã‚’ãƒ‡ã‚³ãƒ¼ãƒ‰
        import urllib.parse
        decoded_url = urllib.parse.unquote(folder_url)

        # ãƒ‘ã‚¹ã‚’æŠ½å‡º
        if "/Documents/" in decoded_url:
            path_part = decoded_url.split("/Documents/")[1]
            # ã‚¯ã‚¨ãƒªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’é™¤å»
            if "?" in path_part:
                path_part = path_part.split("?")[0]

            # ãƒ‘ã‚¹ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
            encoded_path = urllib.parse.quote(path_part)

            # Graph API ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
            drive_id_url = f"https://graph.microsoft.com/v1.0/users/{TARGET_USER_EMAIL}/drive"
            headers = {"Authorization": f"Bearer {access_token}"}

            drive_response = requests.get(drive_id_url, headers=headers)
            if drive_response.status_code != 200:
                print(f"âŒ ãƒ‰ãƒ©ã‚¤ãƒ–æƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {drive_response.status_code}")
                return None

            drive_id = drive_response.json()["id"]

            # ãƒ•ã‚©ãƒ«ãƒ€æƒ…å ±ã‚’å–å¾—
            folder_url = f"https://graph.microsoft.com/v1.0/drives/{drive_id}/root:/{encoded_path}"
            folder_response = requests.get(folder_url, headers=headers)

            if folder_response.status_code == 200:
                return folder_response.json()["id"]
            else:
                print(f"âŒ ãƒ•ã‚©ãƒ«ãƒ€å–å¾—ã‚¨ãƒ©ãƒ¼: {folder_response.status_code}")
                return None

    except Exception as e:
        print(f"âŒ URLè§£æã‚¨ãƒ©ãƒ¼: {e}")
        return None

def get_pdf_files_from_folder(access_token, folder_id):
    """ãƒ•ã‚©ãƒ«ãƒ€å†…ã®PDFãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—"""
    try:
        headers = {"Authorization": f"Bearer {access_token}"}
        url = f"https://graph.microsoft.com/v1.0/users/{TARGET_USER_EMAIL}/drive/items/{folder_id}/children"

        response = requests.get(url, headers=headers)
        if response.status_code != 200:
            print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§å–å¾—ã‚¨ãƒ©ãƒ¼: {response.status_code}")
            print(f"   ãƒ¬ã‚¹ãƒãƒ³ã‚¹: {response.text}")
            return []

        items = response.json().get("value", [])
        pdf_files = [item for item in items if item["name"].lower().endswith(".pdf")]

        return pdf_files

    except Exception as e:
        print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return []

def select_project_files(pdf_files: List[Dict], max_files: int = 5) -> List[Dict]:
    """
    ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠï¼ˆå„ªå…ˆé †ä½ä»˜ãï¼‰
    1. ã€è£œæ­£ã€‘ãŒã¤ã„ã¦ã„ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆæœ€å„ªå…ˆï¼‰
    2. ã€ä¿®æ­£ã€‘ãŒã¤ã„ã¦ã„ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆæ¬¡å„ªå…ˆï¼‰
    3. ãã®ä»–ã®ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆä½œæˆæ—¥æ™‚ãŒæ–°ã—ã„é †ï¼‰
    """
    if not pdf_files:
        return []

    # å„ªå…ˆåº¦ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
    def get_priority_score(file_item):
        name = file_item.get("name", "")
        created = file_item.get("createdDateTime", "")

        # åŸºæœ¬ã‚¹ã‚³ã‚¢ï¼ˆæ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«ã»ã©é«˜ã„ï¼‰
        score = 0
        if created:
            try:
                dt = datetime.fromisoformat(created.replace('Z', '+00:00'))
                score = dt.timestamp()
            except:
                score = 0

        # ã€è£œæ­£ã€‘ãƒ•ã‚¡ã‚¤ãƒ«ã«æœ€é«˜å„ªå…ˆåº¦
        if "ã€è£œæ­£ã€‘" in name or "è£œæ­£" in name:
            score += 10000000000
        # ã€ä¿®æ­£ã€‘ãƒ•ã‚¡ã‚¤ãƒ«ã«æ¬¡ã®å„ªå…ˆåº¦
        elif "ã€ä¿®æ­£ã€‘" in name or "ä¿®æ­£" in name:
            score += 5000000000

        return score

    # ã‚¹ã‚³ã‚¢ã§ã‚½ãƒ¼ãƒˆ
    sorted_files = sorted(pdf_files, key=get_priority_score, reverse=True)

    # ä¸Šä½max_filesä»¶ã‚’è¿”ã™
    return sorted_files[:max_files]

def download_pdf(access_token, file_id):
    """PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
    try:
        headers = {"Authorization": f"Bearer {access_token}"}
        download_url = f"https://graph.microsoft.com/v1.0/users/{TARGET_USER_EMAIL}/drive/items/{file_id}/content"

        response = requests.get(download_url, headers=headers)
        if response.status_code == 200:
            return response.content
        else:
            print(f"âŒ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {response.status_code}")
            return None

    except Exception as e:
        print(f"âŒ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
        return None

def analyze_with_gemini_with_retry(pdf_contents: List[bytes], metadata: Dict) -> Dict:
    """
    Gemini 2.0 Flashã§PDFã‚’è§£æï¼ˆãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ä»˜ãï¼‰
    """
    vertexai.init(project=GCP_PROJECT_ID, location=LOCATION)
    model = GenerativeModel("gemini-2.0-flash-exp")

    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
    prompt = """
ã‚ãªãŸã¯æ§‹é€ è¨­è¨ˆã®å°‚é–€å®¶ã§ã™ã€‚æä¾›ã•ã‚ŒãŸæ§‹é€ è¨ˆç®—æ›¸PDFã‹ã‚‰ã€ä»¥ä¸‹ã®æƒ…å ±ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚

ã€æŠ½å‡ºé …ç›®ã€‘
1. åŸºæœ¬æƒ…å ±
   - structure_type: æ§‹é€ ç¨®åˆ¥ï¼ˆæœ¨é€ /RCé€ /Sé€ /SRCé€ ãªã©ï¼‰
   - primary_use: ä¸»è¦ç”¨é€”ï¼ˆæˆ¸å»ºä½å®…/å…±åŒä½å®…/äº‹å‹™æ‰€/åº—èˆ—ãªã©ï¼‰
   - floors: éšæ•°ï¼ˆåœ°ä¸Šâ—‹éšã€åœ°ä¸‹â—‹éšã®å½¢å¼ï¼‰
   - total_floor_area: å»¶åºŠé¢ç©ï¼ˆæ•°å€¤ + å˜ä½ï¼‰

2. æ³•çš„ãƒ»æŠ€è¡“æƒ…å ±
   - performance_requirements: æ€§èƒ½è¦ä»¶ï¼ˆè€éœ‡ç­‰ç´šã€çœä»¤æº–è€ç«ãªã©ï¼‰
   - structural_calc_route: æ§‹é€ è¨ˆç®—ãƒ«ãƒ¼ãƒˆï¼ˆè¨±å®¹å¿œåŠ›åº¦è¨ˆç®—/æ€§èƒ½è¡¨ç¤ºè¨ˆç®—/é™ç•Œè€åŠ›è¨ˆç®—ãªã©ï¼‰
   - route_reasoning: ãƒ«ãƒ¼ãƒˆé¸å®šç†ç”±
   - foundation_type: åŸºç¤å½¢å¼ï¼ˆã¹ãŸåŸºç¤/å¸ƒåŸºç¤/æ­åŸºç¤ãªã©ï¼‰
   - design_features: è¨­è¨ˆä¸Šã®ç‰¹å¾´ã‚„å·¥å¤«
   - lateral_resistance: è€åŠ›è¦ç´ ï¼ˆè€åŠ›å£/ãƒ–ãƒ¬ãƒ¼ã‚¹/ãƒ©ãƒ¼ãƒ¡ãƒ³ãªã©ï¼‰

3. ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¡ä»¶
   - regional_conditions: åœ°åŸŸæ¡ä»¶ï¼ˆç©é›ª/å‡çµæ·±åº¦/é¢¨é€Ÿãªã©ï¼‰
   - ground_condition: åœ°ç›¤çŠ¶æ³ï¼ˆNå€¤ã€åœ°ç›¤æ”¹è‰¯ã®æœ‰ç„¡ãªã©ï¼‰
   - inspection_agency: æ¤œæŸ»æ©Ÿé–¢ãƒ»ç¢ºèªæ¤œæŸ»æ©Ÿé–¢

4. ãã®ä»–
   - project_summary: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¦‚è¦ï¼ˆ100æ–‡å­—ç¨‹åº¦ï¼‰
   - project_name: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåç§°
   - calc_book_date: è¨ˆç®—æ›¸æ—¥ä»˜
   - software: ä½¿ç”¨ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢

ã€å‡ºåŠ›å½¢å¼ã€‘
å¿…ãšJSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚æƒ…å ±ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯nullã¨ã—ã¦ãã ã•ã„ã€‚

{
  "structure_type": "...",
  "primary_use": "...",
  "floors": "...",
  "total_floor_area": "...",
  "performance_requirements": "...",
  "structural_calc_route": "...",
  "route_reasoning": "...",
  "foundation_type": "...",
  "design_features": "...",
  "lateral_resistance": "...",
  "regional_conditions": "...",
  "ground_condition": "...",
  "inspection_agency": "...",
  "project_summary": "...",
  "project_name": "...",
  "calc_book_date": "...",
  "software": "..."
}
"""

    # PDFã‚’Partã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å¤‰æ›
    parts = [Part.from_data(pdf_content, mime_type="application/pdf") for pdf_content in pdf_contents]
    parts.insert(0, prompt)

    # ãƒªãƒˆãƒ©ã‚¤ãƒ­ã‚¸ãƒƒã‚¯
    for attempt in range(MAX_RETRIES):
        try:
            # ãƒ©ãƒ³ãƒ€ãƒ ãªåˆæœŸé…å»¶ï¼ˆè² è·åˆ†æ•£ï¼‰
            if attempt == 0:
                initial_delay = random.uniform(0, 2)
                time.sleep(initial_delay)

            # Gemini APIå‘¼ã³å‡ºã—
            response = model.generate_content(
                parts,
                generation_config=GenerationConfig(
                    temperature=0.1,
                    max_output_tokens=8192,
                )
            )

            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
            result_text = response.text.strip()

            # JSONãƒ–ãƒ­ãƒƒã‚¯ã‚’æŠ½å‡º
            if "```json" in result_text:
                json_start = result_text.find("```json") + 7
                json_end = result_text.find("```", json_start)
                result_text = result_text[json_start:json_end].strip()
            elif "```" in result_text:
                json_start = result_text.find("```") + 3
                json_end = result_text.find("```", json_start)
                result_text = result_text[json_start:json_end].strip()

            # JSONãƒ‘ãƒ¼ã‚¹
            extracted_data = json.loads(result_text)

            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æ¤œæŸ»æ©Ÿé–¢ã‚’è£œå®Œ
            if not extracted_data.get("inspection_agency") and metadata.get("clientName"):
                extracted_data["inspection_agency"] = metadata["clientName"]

            print(f"âœ… Geminiè§£ææˆåŠŸï¼ˆè©¦è¡Œå›æ•°: {attempt + 1}ï¼‰")
            return extracted_data

        except Exception as e:
            error_msg = str(e)
            print(f"âš ï¸ Gemini API ã‚¨ãƒ©ãƒ¼ï¼ˆè©¦è¡Œ {attempt + 1}/{MAX_RETRIES}ï¼‰: {error_msg}")

            # 429ã‚¨ãƒ©ãƒ¼ï¼ˆãƒ¬ãƒ¼ãƒˆåˆ¶é™ï¼‰ã®å ´åˆ
            if "429" in error_msg or "RESOURCE_EXHAUSTED" in error_msg or "quota" in error_msg.lower():
                if attempt < MAX_RETRIES - 1:
                    # æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ• + ã‚¸ãƒƒã‚¿ãƒ¼
                    delay = min(INITIAL_RETRY_DELAY * (2 ** attempt), MAX_RETRY_DELAY)
                    jitter = random.uniform(-JITTER_RANGE, JITTER_RANGE)
                    wait_time = delay + jitter
                    print(f"â³ ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã«ã‚ˆã‚Š {wait_time:.1f}ç§’å¾…æ©Ÿã—ã¾ã™...")
                    time.sleep(wait_time)
                    continue

            # ãã®ä»–ã®ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯çŸ­ã„å¾…æ©Ÿ
            if attempt < MAX_RETRIES - 1:
                wait_time = 5.0
                print(f"â³ {wait_time}ç§’å¾…æ©Ÿã—ã¦å†è©¦è¡Œã—ã¾ã™...")
                time.sleep(wait_time)

    print(f"âŒ {MAX_RETRIES}å›ã®è©¦è¡Œå¾Œã‚‚å¤±æ•—ã—ã¾ã—ãŸ")
    return {}

def save_to_firestore(project_data: Dict, collection_name: str):
    """Firestoreã«ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜"""
    try:
        db = firestore.Client(project=GCP_PROJECT_ID, database="uplan")

        # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆID: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåã‹ã‚‰ç”Ÿæˆï¼ˆç‰¹æ®Šæ–‡å­—ã‚’é™¤å»ï¼‰
        project_name = project_data.get("project_name", "unknown")
        doc_id = re.sub(r'[^\w\s-]', '', project_name).strip().replace(' ', '_')

        # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’è¿½åŠ ï¼ˆæ—¥æœ¬æ™‚é–“ï¼‰
        project_data["extracted_at"] = datetime.now(JST).isoformat()

        # Firestoreã«ä¿å­˜
        doc_ref = db.collection(collection_name).document(doc_id)
        doc_ref.set(project_data)

        print(f"âœ… Firestoreã«ä¿å­˜ã—ã¾ã—ãŸ: {collection_name}/{doc_id}")
        return True

    except Exception as e:
        print(f"âŒ Firestoreä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
        return False

def process_single_project(project_info: Dict, access_token: str, collection_name: str) -> Dict:
    """1ã¤ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’å‡¦ç†"""
    project_name = project_info["name"]
    folder_url = project_info["url"]
    folder_path = project_info["folder_path"]

    print(f"\n{'='*80}")
    print(f"ğŸ“ å‡¦ç†é–‹å§‹: {project_name}")
    print(f"{'='*80}")

    start_time = time.time()
    result = {
        "project_name": project_name,
        "success": False,
        "error": None,
        "processing_time": 0,
        "extracted_data": {}
    }

    try:
        # 1. ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æŠ½å‡º
        print(f"ğŸ“Š ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºä¸­...")
        metadata = extract_project_metadata(folder_path)
        print(f"   æ§‹é€ ç¨®åˆ¥: {metadata.get('structureType')}")
        print(f"   ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ: {metadata.get('clientName')}")
        print(f"   ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå: {metadata.get('projectName')}")
        print(f"   ä½œæˆæ—¥: {metadata.get('createdDate')}")

        # 2. ãƒ•ã‚©ãƒ«ãƒ€IDã‚’å–å¾—
        print(f"\nğŸ” ãƒ•ã‚©ãƒ«ãƒ€IDå–å¾—ä¸­...")
        folder_id = get_folder_id_from_url(access_token, folder_url)
        if not folder_id:
            raise Exception("ãƒ•ã‚©ãƒ«ãƒ€IDã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
        print(f"   ãƒ•ã‚©ãƒ«ãƒ€ID: {folder_id}")

        # 3. PDFãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—
        print(f"\nğŸ“„ PDFãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢ä¸­...")
        pdf_files = get_pdf_files_from_folder(access_token, folder_id)
        print(f"   è¦‹ã¤ã‹ã£ãŸPDFãƒ•ã‚¡ã‚¤ãƒ«: {len(pdf_files)}ä»¶")

        if not pdf_files:
            raise Exception("PDFãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")

        # 4. ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ
        print(f"\nğŸ¯ ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠä¸­...")
        selected_files = select_project_files(pdf_files, max_files=5)
        print(f"   é¸æŠã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«: {len(selected_files)}ä»¶")
        for i, file in enumerate(selected_files):
            print(f"   {i+1}. {file['name']}")

        # 5. PDFãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        print(f"\nâ¬‡ï¸ PDFãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...")
        pdf_contents = []
        for i, file in enumerate(selected_files):
            print(f"   {i+1}/{len(selected_files)}: {file['name']}")
            content = download_pdf(access_token, file["id"])
            if content:
                pdf_contents.append(content)
                print(f"      âœ… ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº† ({len(content) / 1024 / 1024:.2f} MB)")
            else:
                print(f"      âš ï¸ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•—")

        if not pdf_contents:
            raise Exception("PDFã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ")

        # 6. Geminiè§£æ
        print(f"\nğŸ¤– Gemini AIè§£æä¸­...")
        print(f"   è§£æã™ã‚‹PDFãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(pdf_contents)}")
        extracted_data = analyze_with_gemini_with_retry(pdf_contents, metadata)

        if not extracted_data:
            raise Exception("Geminiè§£æã«å¤±æ•—ã—ã¾ã—ãŸ")

        # 7. ãƒ‡ãƒ¼ã‚¿æ•´å½¢
        project_data = {
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
            "folder_path": folder_path,
            "folder_url": folder_url,
            "folder_id": folder_id,
            "file_count": len(selected_files),
            "client_name": metadata.get("clientName"),
            "created_date": metadata.get("createdDate"),

            # æŠ½å‡ºãƒ‡ãƒ¼ã‚¿
            **extracted_data
        }

        # 8. Firestoreã«ä¿å­˜
        print(f"\nğŸ’¾ Firestoreã«ä¿å­˜ä¸­...")
        save_success = save_to_firestore(project_data, collection_name)

        if not save_success:
            raise Exception("Firestoreä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ")

        # æˆåŠŸ
        result["success"] = True
        result["extracted_data"] = project_data

        elapsed_time = time.time() - start_time
        result["processing_time"] = elapsed_time

        print(f"\nâœ… å‡¦ç†å®Œäº†: {project_name} ({elapsed_time:.1f}ç§’)")

    except Exception as e:
        result["error"] = str(e)
        elapsed_time = time.time() - start_time
        result["processing_time"] = elapsed_time
        print(f"\nâŒ å‡¦ç†å¤±æ•—: {project_name} - {e} ({elapsed_time:.1f}ç§’)")

    return result

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("="*80)
    print("5ç‰©ä»¶ è©³ç´°æŠ½å‡ºãƒ†ã‚¹ãƒˆ")
    print("="*80)

    # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³åï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰
    collection_name = f"Test_5Projects_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    print(f"\nğŸ“¦ ä¿å­˜å…ˆã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³: {collection_name}")

    # ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³å–å¾—
    print(f"\nğŸ” èªè¨¼ä¸­...")
    access_token = get_access_token()
    if not access_token:
        print("âŒ èªè¨¼ã«å¤±æ•—ã—ã¾ã—ãŸ")
        return
    print("âœ… èªè¨¼æˆåŠŸ")

    # å„ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’å‡¦ç†
    results = []
    total_start_time = time.time()

    for i, project_info in enumerate(TEST_PROJECTS):
        print(f"\n\n{'#'*80}")
        print(f"ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ {i+1}/{len(TEST_PROJECTS)}")
        print(f"{'#'*80}")

        result = process_single_project(project_info, access_token, collection_name)
        results.append(result)

        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆé–“ã®å¾…æ©Ÿï¼ˆãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–ï¼‰
        if i < len(TEST_PROJECTS) - 1:
            wait_time = 10.0
            print(f"\nâ³ æ¬¡ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¾ã§{wait_time}ç§’å¾…æ©Ÿ...")
            time.sleep(wait_time)

    # çµæœã‚µãƒãƒªãƒ¼
    total_elapsed_time = time.time() - total_start_time

    print(f"\n\n{'='*80}")
    print("ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼")
    print(f"{'='*80}")
    print(f"ç·å‡¦ç†æ™‚é–“: {total_elapsed_time:.1f}ç§’")
    print(f"å‡¦ç†ä»¶æ•°: {len(results)}ä»¶")

    success_count = sum(1 for r in results if r["success"])
    print(f"æˆåŠŸ: {success_count}ä»¶")
    print(f"å¤±æ•—: {len(results) - success_count}ä»¶")

    print(f"\n{'='*80}")
    print("è©³ç´°çµæœ")
    print(f"{'='*80}")

    for i, result in enumerate(results):
        print(f"\nã€{i+1}ã€‘ {result['project_name']}")
        print(f"   ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {'âœ… æˆåŠŸ' if result['success'] else 'âŒ å¤±æ•—'}")
        print(f"   å‡¦ç†æ™‚é–“: {result['processing_time']:.1f}ç§’")

        if result['success']:
            data = result['extracted_data']
            print(f"   æ§‹é€ ç¨®åˆ¥: {data.get('structure_type', 'N/A')}")
            print(f"   ä¸»è¦ç”¨é€”: {data.get('primary_use', 'N/A')}")
            print(f"   éšæ•°: {data.get('floors', 'N/A')}")
            print(f"   å»¶åºŠé¢ç©: {data.get('total_floor_area', 'N/A')}")
            print(f"   è¨ˆç®—ãƒ«ãƒ¼ãƒˆ: {data.get('structural_calc_route', 'N/A')}")
            print(f"   åŸºç¤å½¢å¼: {data.get('foundation_type', 'N/A')}")
        else:
            print(f"   ã‚¨ãƒ©ãƒ¼: {result['error']}")

    print(f"\n{'='*80}")
    print(f"âœ… ãƒ†ã‚¹ãƒˆå®Œäº†")
    print(f"{'='*80}")

if __name__ == "__main__":
    main()
