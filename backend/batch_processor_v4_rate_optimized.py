"""
Uplan Knowledge Base - Batch Processor v4 (Rate Limit Optimized)

ãƒ¬ãƒ¼ãƒˆåˆ¶é™æœ€é©åŒ–ç‰ˆ:
- ProcessPoolExecutorã«ã‚ˆã‚‹ä¸¦åˆ—å‡¦ç†ã§å„ãƒ—ãƒ­ã‚»ã‚¹ãŒç‹¬ç«‹ã—ãŸãƒ¬ãƒ¼ãƒˆåˆ¶é™æ ã‚’æŒã¤
- æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•ãƒªãƒˆãƒ©ã‚¤æˆ¦ç•¥
- ã‚ˆã‚Šç©æ¥µçš„ãªãƒªãƒˆãƒ©ã‚¤è¨­å®š
- ã‚¿ã‚¹ã‚¯ã”ã¨ã®é©åˆ‡ãªå¾…æ©Ÿæ™‚é–“
- Cloud Run Jobsã§ã®å¤§è¦æ¨¡å‡¦ç†ã«æœ€é©åŒ–
"""

import msal
import requests
import json
import os
import gc
import argparse
import time
import random
from concurrent.futures import ProcessPoolExecutor, as_completed
from typing import List, Dict, Tuple, Optional
import vertexai
from vertexai.generative_models import GenerativeModel, Part, GenerationConfig
from google.cloud import secretmanager
from google.cloud import firestore
from google.api_core import retry, exceptions
from datetime import datetime, timezone, timedelta
import re

# æ—¥æœ¬æ™‚é–“ã®ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³
JST = timezone(timedelta(hours=9))

# --- è¨­å®š ---
GCP_PROJECT_ID = "uplan-knowledge-base"
LOCATION = "us-central1"
TARGET_USER_EMAIL = "info@uplan2018.onmicrosoft.com"

# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
DEFAULT_TARGET_PATH = "001_ï¼µ'plan_å…¨ç¤¾/01.æ§‹é€ è¨­è¨ˆ/01.æœ¨é€ ï¼ˆåœ¨æ¥è»¸çµ„ï¼‰"
DEFAULT_MAX_WORKERS = 10  # ä¸¦åˆ—æ•°ã‚’å¢—ã‚„ã—ã¦ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’åˆ†æ•£
# Firestoreãƒ«ãƒ¼ãƒ«: ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã®ãŸã³ã«æ–°è¦ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’ä½œæˆï¼ˆå½¢å¼: YYYY-MM-DD-HH:MMï¼‰
DEFAULT_COLLECTION = datetime.now().strftime("%Y-%m-%d-%H:%M")

# ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–è¨­å®š
INITIAL_RETRY_DELAY = 2.0  # åˆå›ãƒªãƒˆãƒ©ã‚¤å¾…æ©Ÿæ™‚é–“ï¼ˆç§’ï¼‰
MAX_RETRY_DELAY = 120.0     # æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å¾…æ©Ÿæ™‚é–“ï¼ˆç§’ï¼‰
MAX_RETRIES = 5             # æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°
JITTER_RANGE = 0.5          # ãƒ©ãƒ³ãƒ€ãƒ ã‚¸ãƒƒã‚¿ãƒ¼ç¯„å›²ï¼ˆç§’ï¼‰

# ---------------------------------------------------------

def get_secret(secret_id):
    """Secret Managerã‹ã‚‰ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã‚’å–å¾—"""
    client = secretmanager.SecretManagerServiceClient()
    name = f"projects/{GCP_PROJECT_ID}/secrets/{secret_id}/versions/latest"
    response = client.access_secret_version(request={"name": name})
    return response.payload.data.decode("UTF-8")

def get_access_token():
    """Microsoft Graph APIç”¨ã®ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—"""
    try:
        client_id = get_secret("MS_CLIENT_ID")
        tenant_id = get_secret("MS_TENANT_ID")
        client_secret = get_secret("MS_CLIENT_SECRET")

        authority = f"https://login.microsoftonline.com/{tenant_id}"
        app = msal.ConfidentialClientApplication(client_id, authority=authority, client_credential=client_secret)
        result = app.acquire_token_for_client(scopes=["https://graph.microsoft.com/.default"])
        return result.get("access_token")
    except Exception as e:
        print(f"âŒ èªè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
        return None

def extract_project_metadata(folder_path):
    """ãƒ•ã‚©ãƒ«ãƒ€ãƒ‘ã‚¹ã‹ã‚‰æ¡ˆä»¶ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º"""
    metadata = {
        "structureType": None,
        "clientName": None,
        "projectName": None
    }

    parts = folder_path.split('/')

    for i, part in enumerate(parts):
        if 'æœ¨é€ ' in part:
            metadata["structureType"] = "æœ¨é€ "
            if i + 2 < len(parts):
                client_folder = parts[i + 2]
                match = re.match(r'^[AT]\d+_?(.+?)(?:ï¼ˆ.+?ï¼‰)?$', client_folder)
                if match:
                    metadata["clientName"] = match.group(1).strip()
                    break
                match2 = re.match(r'^\d+\s+(.+)$', client_folder)
                if match2:
                    metadata["clientName"] = match2.group(1).strip()
                    break
        elif 'RC' in part or 'é‰„ç­‹ã‚³ãƒ³ã‚¯ãƒªãƒ¼ãƒˆ' in part:
            metadata["structureType"] = "RCé€ "
        elif 'é‰„éª¨' in part:
            metadata["structureType"] = "Sé€ "

    for part in parts:
        if part.startswith(('2024', '2025', '2026')):
            project_part = part.split('ï¼')[0]
            match = re.match(r'^\d+_(.+)$', project_part)
            if match:
                metadata["projectName"] = match.group(1).strip()
                break

    return metadata

def select_project_files(file_list):
    """ãƒ•ã‚©ãƒ«ãƒ€å†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã€æ§‹é€ è¨ˆç®—æ›¸ãƒ»å›³é¢ãƒ»è¨¼æ˜æ›¸ãƒ»å¯©æŸ»è¡¨ã‚’é¸å®š"""
    all_calc_files = []
    all_drawing_files = []
    safety_certs = []
    review_sheets = []

    for item in file_list:
        if "folder" in item:
            continue

        name = item.get("name", "")
        name_lower = name.lower()

        if not name_lower.endswith(".pdf"):
            continue

        if "æ§‹é€ è¨ˆç®—æ›¸" in name or "è¨ˆç®—æ›¸" in name:
            all_calc_files.append(item)
        elif "æ§‹é€ å›³" in name or "ä¼å›³" in name or "è»¸çµ„å›³" in name:
            all_drawing_files.append(item)
        elif "å®‰å…¨è¨¼æ˜" in name or "é©åˆè¨¼æ˜" in name:
            safety_certs.append(item)
        elif "å¯©æŸ»è¡¨" in name or "ãƒã‚§ãƒƒã‚¯ã‚·ãƒ¼ãƒˆ" in name:
            review_sheets.append(item)

    best_cert = safety_certs[-1] if safety_certs else None
    best_review = review_sheets[-1] if review_sheets else None

    return all_calc_files, all_drawing_files, best_cert, best_review

def exponential_backoff_with_jitter(attempt: int) -> float:
    """æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ• + ãƒ©ãƒ³ãƒ€ãƒ ã‚¸ãƒƒã‚¿ãƒ¼"""
    delay = min(INITIAL_RETRY_DELAY * (2 ** attempt), MAX_RETRY_DELAY)
    jitter = random.uniform(-JITTER_RANGE, JITTER_RANGE)
    return max(0.1, delay + jitter)

def analyze_with_gemini_with_retry(file_data_list, file_name_hints=None, max_attempts=MAX_RETRIES):
    """
    Gemini APIã‚’å‘¼ã³å‡ºã—ï¼ˆç©æ¥µçš„ãªãƒªãƒˆãƒ©ã‚¤æˆ¦ç•¥ï¼‰
    æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ• + ãƒ©ãƒ³ãƒ€ãƒ ã‚¸ãƒƒã‚¿ãƒ¼ã§ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’å›é¿
    """
    vertexai.init(project=GCP_PROJECT_ID, location=LOCATION)
    model = GenerativeModel("gemini-2.0-flash-exp")

    parts = []

    if file_name_hints:
        hint_text = "ã€ãƒ•ã‚¡ã‚¤ãƒ«åãƒ’ãƒ³ãƒˆã€‘\n" + "\n".join([f"- {hint}" for hint in file_name_hints])
        parts.append(hint_text)

    for file_info in file_data_list:
        parts.append(Part.from_data(file_info["data"], mime_type=file_info["mime_type"]))
        parts.append(f"[ãƒ•ã‚¡ã‚¤ãƒ«å: {file_info['name']}]")

    prompt = """
ä»¥ä¸‹ã®æ§‹é€ è¨ˆç®—æ›¸PDFã‚’è§£æã—ã€JSONå½¢å¼ã§æƒ…å ±ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚

ã€æŠ½å‡ºé …ç›®ã¨é¸æŠè‚¢ã€‘

â–  åŸºæœ¬æƒ…å ±
1. æ§‹é€ ç¨®åˆ¥ï¼ˆstructureTypeï¼‰: å˜ä¸€é¸æŠ
   é¸æŠè‚¢: "æœ¨é€ ï¼ˆåœ¨æ¥è»¸çµ„ï¼‰", "æœ¨é€ ï¼ˆé™ç•Œè€åŠ›è¨ˆç®—ï¼‰", "æœ¨é€ ï¼ˆæ çµ„å£ï¼‰", "é‰„éª¨é€ ", "RCé€ ï¼ˆå£å¼ï¼‰", "RCé€ ï¼ˆãƒ©ãƒ¼ãƒ¡ãƒ³ï¼‰"

2. ä¸»è¦ç”¨é€”ï¼ˆprimaryUseï¼‰: å˜ä¸€é¸æŠ
   é¸æŠè‚¢: "æˆ¸å»ºä½å®…", "å…±åŒä½å®…", "åº—èˆ—", "äº‹å‹™æ‰€", "å€‰åº«", "å·¥å ´", "ãã®ä»–"

3. éšæ•°ï¼ˆfloorsï¼‰: å˜ä¸€é¸æŠ
   é¸æŠè‚¢: "å¹³å±‹", "2éšå»ºã¦", "3éšå»ºã¦", "4éšå»ºã¦ä»¥ä¸Š"

4. å»¶åºŠé¢ç©ï¼ˆtotalFloorAreaï¼‰: å˜ä¸€é¸æŠ
   é¸æŠè‚¢: "ã€œ100ã¡", "101ã€œ300ã¡", "301ã€œ1000ã¡", "1001ã¡ã€œ"

â–  æ³•å¾‹ãƒ»æŠ€è¡“çš„è¦ä»¶
5. æ€§èƒ½è¦ä»¶ï¼ˆperformanceRequirementsï¼‰: è¤‡æ•°é¸æŠå¯
   é¸æŠè‚¢: "æº–è€ç«å»ºç¯‰ç‰©", "è€ç«å»ºç¯‰ç‰©", "é•·æœŸå„ªè‰¯ä½å®…", "é©åˆæ€§åˆ¤å®š", "ãã®ä»–"

6. æ§‹é€ è¨ˆç®—ãƒ«ãƒ¼ãƒˆï¼ˆstructuralCalcRouteï¼‰: å˜ä¸€é¸æŠ
   é¸æŠè‚¢: "ãƒ«ãƒ¼ãƒˆ1ï¼ˆè¨±å®¹å¿œåŠ›åº¦è¨ˆç®—ï¼‰", "ãƒ«ãƒ¼ãƒˆ2ï¼ˆè¨±å®¹å¿œåŠ›åº¦ç­‰è¨ˆç®—ï¼‰", "ãƒ«ãƒ¼ãƒˆ3ï¼ˆä¿æœ‰æ°´å¹³è€åŠ›è¨ˆç®—ï¼‰"

7. ãƒ«ãƒ¼ãƒˆåˆ¤å®šã®æ ¹æ‹ ï¼ˆrouteReasoningï¼‰: æ–‡å­—åˆ—ï¼ˆ100æ–‡å­—ç¨‹åº¦ï¼‰

8. åŸºç¤å½¢å¼ï¼ˆfoundationTypeï¼‰: å˜ä¸€é¸æŠ
   é¸æŠè‚¢: "ç›´æ¥åŸºç¤ï¼ˆã¹ãŸåŸºç¤ã€å¸ƒåŸºç¤ãªã©ï¼‰", "æ­åŸºç¤"

9. ç‰¹å¾´çš„ãªè¨­è¨ˆæŠ€è¡“ï¼ˆdesignFeaturesï¼‰: è¤‡æ•°é¸æŠå¯
   é¸æŠè‚¢: "å¤§ã‚¹ãƒ‘ãƒ³ / å¤§é–‹å£", "ã‚¹ã‚­ãƒƒãƒ—ãƒ•ãƒ­ã‚¢", "æœ¨è³ªãƒ©ãƒ¼ãƒ¡ãƒ³", "å¤§å±‹æ ¹", "é‰„éª¨é€ å¤–éƒ¨éšæ®µ", "ç‰‡æŒã¡åŸºç¤ï¼ˆç‰‡æŒã¡ã‚¹ãƒ©ãƒ–ï¼‰", "ã‚¾ãƒ¼ãƒ‹ãƒ³ã‚°", "å¡”å±‹", "ç‰‡æŒã¡åŸºç¤", "æ–œã‚å£"
   æ³¨æ„: ã€Œå¤§å±‹æ ¹ã€ã¯æ§‹é€ è¨ˆç®—æ›¸ã«ã¯è¨˜è¼‰ãŒãªã„ãŸã‚ã€æ§‹é€ å›³ã‹ã‚‰è¦–è¦šçš„ã«åˆ¤å®š

10. æ°´å¹³åŠ›æŠµæŠ—è¦ç´ ï¼ˆlateralResistanceï¼‰: è¤‡æ•°é¸æŠå¯
    é¸æŠè‚¢: "é¢æè€åŠ›å£ï¼ˆæ§‹é€ ç”¨åˆæ¿ã€OSBãªã©ï¼‰", "ç­‹ã‹ã„è€åŠ›å£"

â–  ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®æ¡ä»¶
11. åœ°åŸŸï¼ˆregionalConditionsï¼‰: è¤‡æ•°é¸æŠå¯
    é¸æŠè‚¢: "å¤šé›ªåœ°åŸŸ", "å¡©å®³åœ°åŸŸ", "é˜²ç«ãƒ»æº–é˜²ç«åœ°åŸŸ"
    æ³¨æ„: é¸æŠè‚¢ã«è©²å½“ã—ãªã„å ´åˆã¯ç©ºé…åˆ—

12. åœ°ç›¤æ¡ä»¶ï¼ˆgroundConditionï¼‰: å˜ä¸€é¸æŠ
    é¸æŠè‚¢: "è‰¯å¥½", "è»Ÿå¼±"

13. å¯©æŸ»æ©Ÿé–¢ï¼ˆinspectionAgencyï¼‰: æ–‡å­—åˆ—
    æŠ½å‡ºãƒ«ãƒ¼ãƒ«: æ§‹é€ è¨ˆç®—æ›¸ã«ã¯è¨˜è¼‰ãŒãªã„ã®ã§è³ªç–‘å›ç­”æ›¸ãŒã‚ã‚Œã°æŠ½å‡ºã€ãªã‘ã‚Œã°ç©ºæ–‡å­—åˆ—
    è³ªç–‘å›ç­”æ›¸ã®è¡¨è¨˜æºã‚Œ: è³ªç–‘è§£ç­”æ›¸ã€è³ªç–‘äº‹é …å›ç­”æ›¸ã€æŒ‡æ‘˜å›ç­”æ›¸ã€æŒ‡æ‘˜äº‹é …å›ç­”æ›¸ãªã©

â–  ãã®ä»–
14. ç‰©ä»¶ç‰¹å¾´ã®è¦ç´„ï¼ˆprojectSummaryï¼‰: æ–‡å­—åˆ—ï¼ˆ300æ–‡å­—ç¨‹åº¦ã§è©³ç´°ã«è¦ç´„ï¼‰

15. ç‰©ä»¶åï¼ˆprojectNameï¼‰: æ–‡å­—åˆ—

16. æ§‹é€ è¨ˆç®—æ›¸ã®ä½œæˆå¹´æœˆï¼ˆcalcBookDateï¼‰: æ–‡å­—åˆ—ï¼ˆä¾‹: "2025å¹´3æœˆ"ï¼‰

17. è¨ˆç®—ã‚½ãƒ•ãƒˆï¼ˆsoftwareï¼‰: æ–‡å­—åˆ—

ã€å‡ºåŠ›å½¢å¼ã€‘
ä»¥ä¸‹ã®JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼š

```json
{
  "basic": {
    "structureType": "æœ¨é€ ï¼ˆåœ¨æ¥è»¸çµ„ï¼‰",
    "primaryUse": "æˆ¸å»ºä½å®…",
    "floors": "2éšå»ºã¦",
    "totalFloorArea": "101ã€œ300ã¡"
  },
  "legalTechnical": {
    "performanceRequirements": ["é•·æœŸå„ªè‰¯ä½å®…"],
    "structuralCalcRoute": "ãƒ«ãƒ¼ãƒˆ1ï¼ˆè¨±å®¹å¿œåŠ›åº¦è¨ˆç®—ï¼‰",
    "routeReasoning": "æœ¨é€ 2éšå»ºã¦ã€å»¶åºŠé¢ç©500ã¡æœªæº€ã®ãŸã‚ã€ä»¤ç¬¬82æ¡ã«åŸºã¥ããƒ«ãƒ¼ãƒˆ1ã‚’é©ç”¨",
    "foundationType": "ç›´æ¥åŸºç¤ï¼ˆã¹ãŸåŸºç¤ã€å¸ƒåŸºç¤ãªã©ï¼‰",
    "designFeatures": ["ã‚¹ã‚­ãƒƒãƒ—ãƒ•ãƒ­ã‚¢"],
    "lateralResistance": ["é¢æè€åŠ›å£ï¼ˆæ§‹é€ ç”¨åˆæ¿ã€OSBãªã©ï¼‰", "ç­‹ã‹ã„è€åŠ›å£"]
  },
  "projectConditions": {
    "regionalConditions": ["å¤šé›ªåœ°åŸŸ"],
    "groundCondition": "è‰¯å¥½",
    "inspectionAgency": "æ—¥æœ¬ERI"
  },
  "other": {
    "projectSummary": "æœ¨é€ 2éšå»ºã¦ä½å®…ã®æ§‹é€ è¨­è¨ˆã€‚ã‚¹ã‚­ãƒƒãƒ—ãƒ•ãƒ­ã‚¢ã‚’æ¡ç”¨ã—ã€ç©ºé–“ã®ç«‹ä½“çš„ãªæ§‹æˆãŒç‰¹å¾´ã€‚å¤šé›ªåœ°åŸŸã«å¯¾å¿œã—ãŸç©é›ªè·é‡ã‚’è€ƒæ…®ã€‚è€åŠ›å£ã¯æ§‹é€ ç”¨åˆæ¿ã¨ç­‹ã‹ã„ã‚’ä½µç”¨ã—ã€æ°´å¹³åŠ›ã«å¯¾ã™ã‚‹æŠµæŠ—æ€§èƒ½ã‚’ç¢ºä¿ã€‚ã¹ãŸåŸºç¤ã«ã‚ˆã‚Šè‰¯å¥½ãªåœ°ç›¤æ¡ä»¶ã‚’æ´»ã‹ã—ãŸå®‰å®šã—ãŸåŸºç¤è¨­è¨ˆã‚’å®Ÿç¾ã€‚",
    "projectName": "â—‹â—‹é‚¸æ–°ç¯‰å·¥äº‹",
    "calcBookDate": "2025å¹´3æœˆ",
    "software": "STRDESIGN Ver.17-03"
  }
}
```

ãã‚Œã§ã¯è§£æã‚’é–‹å§‹ã—ã¦ãã ã•ã„ã€‚
"""

    parts.insert(0, prompt)

    # ãƒªãƒˆãƒ©ã‚¤ãƒ«ãƒ¼ãƒ—
    for attempt in range(max_attempts):
        try:
            response = model.generate_content(
                parts,
                generation_config=GenerationConfig(
                    temperature=0.1,
                    top_p=0.95,
                    max_output_tokens=8192,
                )
            )

            text = response.text

            if "```json" in text:
                json_str = text.split("```json")[1].split("```")[0].strip()
            elif "```" in text:
                json_str = text.split("```")[1].split("```")[0].strip()
            else:
                json_str = text.strip()

            result = json.loads(json_str)
            return result

        except exceptions.ResourceExhausted as e:
            # 429ã‚¨ãƒ©ãƒ¼: ãƒ¬ãƒ¼ãƒˆåˆ¶é™
            if attempt < max_attempts - 1:
                delay = exponential_backoff_with_jitter(attempt)
                print(f"   âš ï¸ ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚¨ãƒ©ãƒ¼ (è©¦è¡Œ {attempt + 1}/{max_attempts}): {delay:.1f}ç§’å¾Œã«ãƒªãƒˆãƒ©ã‚¤")
                time.sleep(delay)
            else:
                print(f"   âŒ Geminiè§£æå¤±æ•—: æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°ã«é”ã—ã¾ã—ãŸ")
                return None

        except json.JSONDecodeError as e:
            print(f"   âŒ JSONè§£æã‚¨ãƒ©ãƒ¼: {e}")
            return None

        except Exception as e:
            print(f"   âŒ Geminiè§£æã‚¨ãƒ©ãƒ¼: {e}")
            if attempt < max_attempts - 1:
                delay = exponential_backoff_with_jitter(attempt)
                print(f"   â³ {delay:.1f}ç§’å¾Œã«ãƒªãƒˆãƒ©ã‚¤")
                time.sleep(delay)
            else:
                return None

    return None

def collect_all_project_folders(access_token, user_email, root_path):
    """æŒ‡å®šã•ã‚ŒãŸãƒ«ãƒ¼ãƒˆãƒ‘ã‚¹é…ä¸‹ã®å…¨ã¦ã®æ§‹é€ è¨­è¨ˆå›³æ›¸ãƒ•ã‚©ãƒ«ãƒ€ã‚’åé›†"""
    headers = {"Authorization": f"Bearer {access_token}"}
    project_folders = []

    print(f"ğŸ“‚ ãƒ•ã‚©ãƒ«ãƒ€åé›†é–‹å§‹: {root_path}")

    def scan_folder_recursive(folder_url, current_path="", depth=0):
        """å†å¸°çš„ã«ãƒ•ã‚©ãƒ«ãƒ€ã‚’ã‚¹ã‚­ãƒ£ãƒ³ï¼ˆæ·±ã•åˆ¶é™ä»˜ãï¼‰"""
        if depth > 10:  # æ·±ã•åˆ¶é™
            return

        try:
            response = requests.get(folder_url, headers=headers, timeout=30)
            response.raise_for_status()
            items = response.json().get('value', [])

            for item in items:
                if "folder" not in item:
                    continue

                folder_name = item['name']
                folder_id = item['id']
                new_path = f"{current_path}/{folder_name}".lstrip('/')

                # æ§‹é€ è¨­è¨ˆå›³æ›¸ãƒ•ã‚©ãƒ«ãƒ€ã‚’æ¤œå‡º
                if ('æ§‹é€ è¨­è¨ˆå›³æ›¸' in folder_name or 'æ§‹é€ è¨ˆç®—æ›¸' in folder_name) and 'â—‹' not in folder_name:
                    sub_url = f"https://graph.microsoft.com/v1.0/users/{user_email}/drive/items/{folder_id}/children"
                    sub_response = requests.get(sub_url, headers=headers, timeout=30)
                    if sub_response.status_code == 200:
                        sub_items = sub_response.json().get('value', [])

                        has_sub_folders = False
                        for sub_item in sub_items:
                            if "folder" in sub_item:
                                sub_name = sub_item['name']
                                if ('æ§‹é€ è¨­è¨ˆå›³æ›¸' in sub_name or 'æ§‹é€ è¨ˆç®—æ›¸' in sub_name) and 'â—‹' not in sub_name:
                                    project_folders.append({
                                        'id': sub_item['id'],
                                        'name': sub_item['name'],
                                        'path': current_path,
                                        'full_path': f"{new_path}/{sub_item['name']}"
                                    })
                                    has_sub_folders = True

                        if not has_sub_folders:
                            project_folders.append({
                                'id': folder_id,
                                'name': folder_name,
                                'path': current_path,
                                'full_path': new_path
                            })
                else:
                    # å†å¸°çš„ã«æ¢ç´¢
                    child_url = f"https://graph.microsoft.com/v1.0/users/{user_email}/drive/items/{folder_id}/children"
                    scan_folder_recursive(child_url, new_path, depth + 1)

        except requests.exceptions.Timeout:
            print(f"âš ï¸ ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: {current_path}")
        except Exception as e:
            print(f"âš ï¸ ãƒ•ã‚©ãƒ«ãƒ€ã‚¹ã‚­ãƒ£ãƒ³ã‚¨ãƒ©ãƒ¼ ({current_path}): {e}")

    start_url = f"https://graph.microsoft.com/v1.0/users/{user_email}/drive/root:/{root_path}:/children"
    scan_folder_recursive(start_url, root_path)

    print(f"âœ… ãƒ•ã‚©ãƒ«ãƒ€åé›†å®Œäº†: {len(project_folders)}ä»¶ã®æ¡ˆä»¶ã‚’æ¤œå‡º")
    return project_folders

def process_single_project(project_info: Dict, access_token: str, user_email: str, collection_name: str) -> Tuple[bool, str, float]:
    """
    å˜ä¸€ã®æ¡ˆä»¶ãƒ•ã‚©ãƒ«ãƒ€ã‚’å‡¦ç†ï¼ˆä¸¦åˆ—å®Ÿè¡Œã•ã‚Œã‚‹ï¼‰
    å„ãƒ—ãƒ­ã‚»ã‚¹ãŒç‹¬ç«‹ã—ãŸãƒ¬ãƒ¼ãƒˆåˆ¶é™æ ã‚’æŒã¤
    """
    folder_id = project_info['id']
    folder_name = project_info['name']
    full_path = project_info['full_path']

    headers = {"Authorization": f"Bearer {access_token}"}

    try:
        # å‡¦ç†é–‹å§‹æ™‚ã«ãƒ©ãƒ³ãƒ€ãƒ ãªåˆæœŸé…å»¶ã‚’å…¥ã‚Œã¦ã€ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’åˆ†æ•£
        initial_delay = random.uniform(0, 2.0)
        time.sleep(initial_delay)

        # ãƒ•ã‚©ãƒ«ãƒ€ã®è©³ç´°æƒ…å ±ã¨webUrlã‚’å–å¾—
        folder_detail_url = f"https://graph.microsoft.com/v1.0/users/{user_email}/drive/items/{folder_id}"
        folder_detail_response = requests.get(folder_detail_url, headers=headers, timeout=30)
        folder_detail_response.raise_for_status()
        folder_detail = folder_detail_response.json()
        folder_web_url = folder_detail.get('webUrl', '')

        # ãƒ•ã‚©ãƒ«ãƒ€å†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—
        folder_url = f"https://graph.microsoft.com/v1.0/users/{user_email}/drive/items/{folder_id}/children"
        response = requests.get(folder_url, headers=headers, timeout=60)
        response.raise_for_status()
        items = response.json().get('value', [])

        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸å®š
        calc_files, drawing_files, cert_file, review_file = select_project_files(items)

        if not calc_files:
            return False, f"æ§‹é€ è¨ˆç®—æ›¸PDFãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“", 0.0

        # é‡è¤‡ãƒã‚§ãƒƒã‚¯
        db = firestore.Client(project=GCP_PROJECT_ID, database="uplan")
        existing_query = db.collection(collection_name).where("file_id", "==", folder_id).limit(1).stream()
        existing_docs = list(existing_query)

        if len(existing_docs) > 0:
            existing_doc = existing_docs[0]
            existing_data = existing_doc.to_dict()
            existing_project_name = existing_data.get('project_name', 'N/A')
            return False, f"ã‚¹ã‚­ãƒƒãƒ—ï¼ˆç™»éŒ²æ¸ˆã¿: {existing_project_name}ï¼‰", 0.0

        # ãƒ•ã‚©ãƒ«ãƒ€åã‹ã‚‰ä½œæˆå¹´æœˆã‚’æŠ½å‡º
        created_year_month = None
        date_match = re.match(r'^(\d{4})(\d{2})\d{2}', folder_name)
        if date_match:
            year = date_match.group(1)
            month = date_match.group(2).lstrip('0')
            created_year_month = f"{year}å¹´{month}æœˆ"

        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåã‚’æŠ½å‡º
        project_name = None
        path_parts = full_path.split('/')
        if len(path_parts) >= 5:
            last_part = path_parts[-1]
            if not re.match(r'^\d{4,7}_', last_part):
                project_name = last_part
            elif len(path_parts) >= 6:
                number_folder = last_part
                name_match = re.match(r'^\d{4,7}_(.+?)(?:ï¼|$)', number_folder)
                if name_match:
                    project_name = name_match.group(1)

        # PDFã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        file_data_list = []
        file_name_hints = []

        for pdf_file in calc_files[:5]:
            download_url = pdf_file.get('@microsoft.graph.downloadUrl')
            if download_url:
                pdf_response = requests.get(download_url, timeout=120)
                if pdf_response.status_code == 200:
                    file_data_list.append({
                        "data": pdf_response.content,
                        "mime_type": "application/pdf",
                        "name": pdf_file['name']
                    })
                    file_name_hints.append(pdf_file['name'])

        if not file_data_list:
            return False, "PDFãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•—", 0.0

        # Gemini APIã§è§£æï¼ˆç©æ¥µçš„ãªãƒªãƒˆãƒ©ã‚¤ï¼‰
        start_time = time.time()
        analysis_result = analyze_with_gemini_with_retry(file_data_list, file_name_hints)
        elapsed = time.time() - start_time

        del file_data_list
        gc.collect()

        if not analysis_result:
            return False, "AIè§£æå¤±æ•—", elapsed

        # ãƒ•ã‚©ãƒ«ãƒ€ãƒ‘ã‚¹ã‹ã‚‰ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æŠ½å‡º
        metadata = extract_project_metadata(full_path)

        # è§£æçµæœã‚’å–å¾—
        basic = analysis_result.get("basic", {})
        legal_technical = analysis_result.get("legalTechnical", {})
        project_conditions = analysis_result.get("projectConditions", {})
        other = analysis_result.get("other", {})

        # Firestoreã«ä¿å­˜
        # Firestoreãƒ«ãƒ¼ãƒ«: ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆIDã¯ç‰©ä»¶åã‚’ãã®ã¾ã¾ä½¿ç”¨ï¼ˆç‰¹æ®Šæ–‡å­—ã®ã¿ç½®æ›ï¼‰
        doc_id = (other.get("projectName", project_name) or "ä¸æ˜ç‰©ä»¶").replace("/", "-").replace(":", "-")

        # å–å¼•å…ˆåã‚’ãƒ•ã‚©ãƒ«ãƒ€ãƒ‘ã‚¹ã‹ã‚‰æŠ½å‡º
        client_name = metadata['clientName'] or ""

        save_data = {
            # åŸºæœ¬æƒ…å ±
            "structure_type": basic.get("structureType", ""),
            "primary_use": basic.get("primaryUse", ""),
            "floors": basic.get("floors", ""),
            "total_floor_area": basic.get("totalFloorArea", ""),

            # æ³•å¾‹ãƒ»æŠ€è¡“çš„è¦ä»¶
            "performance_requirements": legal_technical.get("performanceRequirements", []),
            "structural_calc_route": legal_technical.get("structuralCalcRoute", ""),
            "route_reasoning": legal_technical.get("routeReasoning", ""),
            "foundation_type": legal_technical.get("foundationType", ""),
            "design_features": legal_technical.get("designFeatures", []),
            "lateral_resistance": legal_technical.get("lateralResistance", []),

            # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®æ¡ä»¶
            "regional_conditions": project_conditions.get("regionalConditions", []),
            "ground_condition": project_conditions.get("groundCondition", ""),
            "client_name": client_name,
            "inspection_agency": project_conditions.get("inspectionAgency", ""),

            # ãã®ä»–
            "project_summary": other.get("projectSummary", ""),
            "project_name": other.get("projectName", project_name or ""),
            "calc_book_date": other.get("calcBookDate", created_year_month or ""),
            "software": other.get("software", ""),

            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
            "folder_url": folder_web_url,
            "extracted_at": datetime.now(JST).isoformat(),
            "file_id": folder_id,
            "folder_name": folder_name,
            "folder_path": full_path,
            "file_count": {
                "calc": len(calc_files),
                "drawing": len(drawing_files),
                "cert": 1 if cert_file else 0,
                "review": 1 if review_file else 0
            },

            # ç”Ÿã®è§£æçµæœã‚’ä¿å­˜ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
            "raw_analysis_result": analysis_result
        }

        collection_ref = db.collection(collection_name)
        collection_ref.document(doc_id).set(save_data)

        return True, f"æˆåŠŸ: {len(calc_files)}ãƒ•ã‚¡ã‚¤ãƒ«è§£æ", elapsed

    except Exception as e:
        return False, f"ã‚¨ãƒ©ãƒ¼: {str(e)[:100]}", 0.0

def process_projects_parallel(project_folders: List[Dict], max_workers: int, collection_name: str):
    """
    è¤‡æ•°ã®æ¡ˆä»¶ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä¸¦åˆ—å‡¦ç†
    å„ãƒ¯ãƒ¼ã‚«ãƒ¼ãŒç‹¬ç«‹ã—ãŸãƒ—ãƒ­ã‚»ã‚¹ã§å®Ÿè¡Œã•ã‚Œã‚‹ãŸã‚ã€ãƒ¬ãƒ¼ãƒˆåˆ¶é™ãŒåˆ†æ•£ã•ã‚Œã‚‹
    """
    print(f"\nğŸš€ ä¸¦åˆ—å‡¦ç†é–‹å§‹: {len(project_folders)}ä»¶ã‚’{max_workers}ä¸¦åˆ—ã§å‡¦ç†")
    print(f"ğŸ’¡ ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–: å„ãƒ¯ãƒ¼ã‚«ãƒ¼ãŒç‹¬ç«‹ã—ãŸãƒ¬ãƒ¼ãƒˆåˆ¶é™æ ã‚’æŒã¡ã¾ã™")

    token = get_access_token()
    if not token:
        print("âŒ èªè¨¼å¤±æ•—")
        return

    success_count = 0
    error_count = 0
    skipped_count = 0
    total_elapsed = 0.0

    with ProcessPoolExecutor(max_workers=max_workers) as executor:
        future_to_project = {
            executor.submit(process_single_project, project, token, TARGET_USER_EMAIL, collection_name): project
            for project in project_folders
        }

        for future in as_completed(future_to_project):
            project = future_to_project[future]
            try:
                success, message, elapsed = future.result()
                total_elapsed += elapsed

                if success:
                    success_count += 1
                    print(f"âœ… [{success_count + error_count + skipped_count}/{len(project_folders)}] {project['name']}: {message} ({elapsed:.1f}ç§’)")
                elif "ã‚¹ã‚­ãƒƒãƒ—" in message:
                    skipped_count += 1
                    print(f"â­ï¸  [{success_count + error_count + skipped_count}/{len(project_folders)}] {project['name']}: {message}")
                else:
                    error_count += 1
                    print(f"âŒ [{success_count + error_count + skipped_count}/{len(project_folders)}] {project['name']}: {message}")

            except Exception as e:
                error_count += 1
                print(f"âŒ [{success_count + error_count + skipped_count}/{len(project_folders)}] {project['name']}: ä¾‹å¤– - {str(e)[:100]}")

    avg_time = total_elapsed / success_count if success_count > 0 else 0

    print(f"\nğŸ“Š å‡¦ç†å®Œäº†: æˆåŠŸ {success_count}ä»¶ / ã‚¹ã‚­ãƒƒãƒ— {skipped_count}ä»¶ / ã‚¨ãƒ©ãƒ¼ {error_count}ä»¶ / åˆè¨ˆ {len(project_folders)}ä»¶")
    print(f"â±ï¸  å¹³å‡å‡¦ç†æ™‚é–“: {avg_time:.1f}ç§’/ä»¶")
    print(f"â±ï¸  ç·å‡¦ç†æ™‚é–“: {total_elapsed:.1f}ç§’ ({total_elapsed/60:.1f}åˆ†)")

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    start_time = time.time()
    start_datetime = datetime.now()

    parser = argparse.ArgumentParser(description='Uplan Knowledge Base - Batch Processor v4 (Rate Limit Optimized)')
    parser.add_argument('--target-path', type=str, default=DEFAULT_TARGET_PATH,
                       help=f'æŠ½å‡ºå¯¾è±¡ã®ãƒ«ãƒ¼ãƒˆãƒ‘ã‚¹ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {DEFAULT_TARGET_PATH})')
    parser.add_argument('--workers', type=int, default=DEFAULT_MAX_WORKERS,
                       help=f'ä¸¦åˆ—å‡¦ç†æ•° (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {DEFAULT_MAX_WORKERS})')
    parser.add_argument('--collection', type=str, default=DEFAULT_COLLECTION,
                       help=f'ä¿å­˜å…ˆã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {DEFAULT_COLLECTION})')

    args = parser.parse_args()

    print("=" * 80)
    print("ğŸš€ Uplan Knowledge Base - Batch Processor v4 (Rate Limit Optimized)")
    print("=" * 80)
    print(f"ğŸ“‚ ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ‘ã‚¹: {args.target_path}")
    print(f"âš™ï¸  ä¸¦åˆ—å‡¦ç†æ•°: {args.workers}")
    print(f"ğŸ’¾ ä¿å­˜å…ˆã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³: {args.collection}")
    print(f"â° é–‹å§‹æ™‚åˆ»: {start_datetime.strftime('%Y/%m/%d %H:%M:%S')}")
    print(f"ğŸ”„ ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–: æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ• + ãƒ©ãƒ³ãƒ€ãƒ ã‚¸ãƒƒã‚¿ãƒ¼ + ãƒ—ãƒ­ã‚»ã‚¹åˆ†æ•£")
    print("=" * 80)

    # èªè¨¼
    token = get_access_token()
    if not token:
        print("âŒ èªè¨¼å¤±æ•—ã®ãŸã‚çµ‚äº†ã—ã¾ã™")
        return

    # ãƒ•ã‚©ãƒ«ãƒ€åé›†
    project_folders = collect_all_project_folders(token, TARGET_USER_EMAIL, args.target_path)

    if not project_folders:
        print("âš ï¸ æ¡ˆä»¶ãƒ•ã‚©ãƒ«ãƒ€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        return

    # ä¸¦åˆ—å‡¦ç†
    process_projects_parallel(project_folders, max_workers=args.workers, collection_name=args.collection)

    # å®Ÿè¡Œæ™‚é–“ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°çµ‚äº†
    end_time = time.time()
    end_datetime = datetime.now()
    elapsed_seconds = int(end_time - start_time)
    elapsed_minutes = elapsed_seconds // 60
    elapsed_seconds_remainder = elapsed_seconds % 60

    print("\n" + "=" * 80)
    print("ğŸ‰ å…¨å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸ")
    print("=" * 80)
    print(f"â° é–‹å§‹æ™‚åˆ»: {start_datetime.strftime('%Y/%m/%d %H:%M:%S')}")
    print(f"â° çµ‚äº†æ™‚åˆ»: {end_datetime.strftime('%Y/%m/%d %H:%M:%S')}")
    print(f"â±ï¸  å‡¦ç†æ™‚é–“: {elapsed_minutes}åˆ†{elapsed_seconds_remainder}ç§’")
    print("=" * 80)

if __name__ == "__main__":
    main()
